{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybEz77MCfnnv"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AI4Finance-Foundation/FinRL-Tutorials/blob/master/3-Practical/FinRL_PaperTrading_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a >"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3mbRu3s1YlD"
      },
      "source": [
        "# Part 1: Install FinRL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0gkmsPgbvNf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2a0bbb99-1b5b-4fb3-b6b5-ec9be009da0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wrds\n",
            "  Downloading wrds-3.2.0-py3-none-any.whl (13 kB)\n",
            "Collecting numpy<1.27,>=1.26 (from wrds)\n",
            "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging<23.3 (from wrds)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pandas<2.3,>=2.2 (from wrds)\n",
            "  Downloading pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting psycopg2-binary<2.10,>=2.9 (from wrds)\n",
            "  Downloading psycopg2_binary-2.9.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy<1.13,>=1.12 (from wrds)\n",
            "  Downloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.4/38.4 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sqlalchemy<2.1,>=2 in /usr/local/lib/python3.10/dist-packages (from wrds) (2.0.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<2.3,>=2.2->wrds) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.3,>=2.2->wrds) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<2.3,>=2.2->wrds) (2024.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<2.1,>=2->wrds) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<2.1,>=2->wrds) (3.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<2.3,>=2.2->wrds) (1.16.0)\n",
            "Installing collected packages: psycopg2-binary, packaging, numpy, scipy, pandas, wrds\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.1\n",
            "    Uninstalling packaging-24.1:\n",
            "      Successfully uninstalled packaging-24.1\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.25.2\n",
            "    Uninstalling numpy-1.25.2:\n",
            "      Successfully uninstalled numpy-1.25.2\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.11.4\n",
            "    Uninstalling scipy-1.11.4:\n",
            "      Successfully uninstalled scipy-1.11.4\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.0.3\n",
            "    Uninstalling pandas-2.0.3:\n",
            "      Successfully uninstalled pandas-2.0.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pandas<2.2.2dev0,>=2.0, but you have pandas 2.2.2 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.0.3, but you have pandas 2.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4 packaging-23.2 pandas-2.2.2 psycopg2-binary-2.9.9 scipy-1.12.0 wrds-3.2.0\n",
            "Collecting swig\n",
            "  Downloading swig-4.2.1-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: swig\n",
            "Successfully installed swig-4.2.1\n",
            "⏬ Downloading https://github.com/conda-forge/miniforge/releases/download/23.11.0-0/Mambaforge-23.11.0-0-Linux-x86_64.sh...\n",
            "📦 Installing...\n",
            "📌 Adjusting configuration...\n",
            "🩹 Patching environment...\n",
            "⏲ Done in 0:00:12\n",
            "🔁 Restarting kernel...\n",
            "Selecting previously unselected package libgl1-mesa-glx:amd64.\n",
            "(Reading database ... 121925 files and directories currently installed.)\n",
            "Preparing to unpack .../libgl1-mesa-glx_23.0.4-0ubuntu1~22.04.1_amd64.deb ...\n",
            "Unpacking libgl1-mesa-glx:amd64 (23.0.4-0ubuntu1~22.04.1) ...\n",
            "Selecting previously unselected package swig4.0.\n",
            "Preparing to unpack .../swig4.0_4.0.2-1ubuntu1_amd64.deb ...\n",
            "Unpacking swig4.0 (4.0.2-1ubuntu1) ...\n",
            "Selecting previously unselected package swig.\n",
            "Preparing to unpack .../swig_4.0.2-1ubuntu1_all.deb ...\n",
            "Unpacking swig (4.0.2-1ubuntu1) ...\n",
            "Setting up libgl1-mesa-glx:amd64 (23.0.4-0ubuntu1~22.04.1) ...\n",
            "Setting up swig4.0 (4.0.2-1ubuntu1) ...\n",
            "Setting up swig (4.0.2-1ubuntu1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Collecting git+https://github.com/AI4Finance-Foundation/FinRL.git\n",
            "  Cloning https://github.com/AI4Finance-Foundation/FinRL.git to /tmp/pip-req-build-9z4wej3x\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/AI4Finance-Foundation/FinRL.git /tmp/pip-req-build-9z4wej3x\n",
            "  Resolved https://github.com/AI4Finance-Foundation/FinRL.git to commit c7c0429a14f94fd2a460558bb49240e184f8d32d\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl (from finrl==0.3.6)\n",
            "  Cloning https://github.com/AI4Finance-Foundation/ElegantRL.git to /tmp/pip-install-ov1r1o5d/elegantrl_ba58648d272e438e81eb8d326211a6e4\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/AI4Finance-Foundation/ElegantRL.git /tmp/pip-install-ov1r1o5d/elegantrl_ba58648d272e438e81eb8d326211a6e4\n",
            "  Resolved https://github.com/AI4Finance-Foundation/ElegantRL.git to commit 6ead2cbd17e4ecd3942fc8a394719db1515cf13f\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting alpaca-trade-api<4,>=3 (from finrl==0.3.6)\n",
            "  Downloading alpaca_trade_api-3.2.0-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting ccxt<4,>=3 (from finrl==0.3.6)\n",
            "  Downloading ccxt-3.1.60-py2.py3-none-any.whl.metadata (108 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.7/108.7 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting exchange-calendars<5,>=4 (from finrl==0.3.6)\n",
            "  Downloading exchange_calendars-4.5.5-py3-none-any.whl.metadata (37 kB)\n",
            "Collecting jqdatasdk<2,>=1 (from finrl==0.3.6)\n",
            "  Downloading jqdatasdk-1.9.5-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting pyfolio<0.10,>=0.9 (from finrl==0.3.6)\n",
            "  Downloading pyfolio-0.9.2.tar.gz (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.1/91.1 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pyportfolioopt<2,>=1 (from finrl==0.3.6)\n",
            "  Downloading pyportfolioopt-1.5.5-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting ray<3,>=2 (from ray[default,tune]<3,>=2->finrl==0.3.6)\n",
            "  Downloading ray-2.31.0-cp310-cp310-manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Collecting scikit-learn<2,>=1 (from finrl==0.3.6)\n",
            "  Downloading scikit_learn-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting stable-baselines3>=2.0.0a5 (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
            "  Downloading stable_baselines3-2.4.0a4-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting stockstats<0.6,>=0.5 (from finrl==0.3.6)\n",
            "  Downloading stockstats-0.5.4-py2.py3-none-any.whl.metadata (26 kB)\n",
            "Collecting wrds<4,>=3 (from finrl==0.3.6)\n",
            "  Downloading wrds-3.2.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting yfinance<0.3,>=0.2 (from finrl==0.3.6)\n",
            "  Downloading yfinance-0.2.40-py2.py3-none-any.whl.metadata (11 kB)\n",
            "Collecting pandas>=0.18.1 (from alpaca-trade-api<4,>=3->finrl==0.3.6)\n",
            "  Downloading pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Collecting numpy>=1.11.1 (from alpaca-trade-api<4,>=3->finrl==0.3.6)\n",
            "  Downloading numpy-2.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>2 in /usr/local/lib/python3.10/site-packages (from alpaca-trade-api<4,>=3->finrl==0.3.6) (2.31.0)\n",
            "Collecting urllib3<2,>1.24 (from alpaca-trade-api<4,>=3->finrl==0.3.6)\n",
            "  Downloading urllib3-1.26.19-py2.py3-none-any.whl.metadata (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websocket-client<2,>=0.56.0 (from alpaca-trade-api<4,>=3->finrl==0.3.6)\n",
            "  Downloading websocket_client-1.8.0-py3-none-any.whl.metadata (8.0 kB)\n",
            "Collecting websockets<11,>=9.0 (from alpaca-trade-api<4,>=3->finrl==0.3.6)\n",
            "  Downloading websockets-10.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
            "Collecting msgpack==1.0.3 (from alpaca-trade-api<4,>=3->finrl==0.3.6)\n",
            "  Downloading msgpack-1.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.7 kB)\n",
            "Collecting aiohttp<4,>=3.8.3 (from alpaca-trade-api<4,>=3->finrl==0.3.6)\n",
            "  Downloading aiohttp-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n",
            "Collecting PyYAML==6.0.1 (from alpaca-trade-api<4,>=3->finrl==0.3.6)\n",
            "  Downloading PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting deprecation==2.1.0 (from alpaca-trade-api<4,>=3->finrl==0.3.6)\n",
            "  Downloading deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/site-packages (from deprecation==2.1.0->alpaca-trade-api<4,>=3->finrl==0.3.6) (23.2)\n",
            "Requirement already satisfied: setuptools>=60.9.0 in /usr/local/lib/python3.10/site-packages (from ccxt<4,>=3->finrl==0.3.6) (68.2.2)\n",
            "Requirement already satisfied: certifi>=2018.1.18 in /usr/local/lib/python3.10/site-packages (from ccxt<4,>=3->finrl==0.3.6) (2023.11.17)\n",
            "Collecting cryptography>=2.6.1 (from ccxt<4,>=3->finrl==0.3.6)\n",
            "  Downloading cryptography-42.0.8-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
            "Collecting aiodns>=1.1.1 (from ccxt<4,>=3->finrl==0.3.6)\n",
            "  Downloading aiodns-3.2.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting yarl>=1.7.2 (from ccxt<4,>=3->finrl==0.3.6)\n",
            "  Downloading yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
            "Collecting pyluach (from exchange-calendars<5,>=4->finrl==0.3.6)\n",
            "  Downloading pyluach-2.2.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting toolz (from exchange-calendars<5,>=4->finrl==0.3.6)\n",
            "  Downloading toolz-0.12.1-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting tzdata (from exchange-calendars<5,>=4->finrl==0.3.6)\n",
            "  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting korean-lunar-calendar (from exchange-calendars<5,>=4->finrl==0.3.6)\n",
            "  Downloading korean_lunar_calendar-0.3.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting six (from jqdatasdk<2,>=1->finrl==0.3.6)\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting SQLAlchemy>=1.2.8 (from jqdatasdk<2,>=1->finrl==0.3.6)\n",
            "  Downloading SQLAlchemy-2.0.31-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Collecting pymysql>=0.7.6 (from jqdatasdk<2,>=1->finrl==0.3.6)\n",
            "  Downloading PyMySQL-1.1.1-py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting thriftpy2>=0.3.9 (from jqdatasdk<2,>=1->finrl==0.3.6)\n",
            "  Downloading thriftpy2-0.5.1.tar.gz (781 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.6/781.6 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ipython>=3.2.3 (from pyfolio<0.10,>=0.9->finrl==0.3.6)\n",
            "  Downloading ipython-8.26.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting matplotlib>=1.4.0 (from pyfolio<0.10,>=0.9->finrl==0.3.6)\n",
            "  Downloading matplotlib-3.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting pytz>=2014.10 (from pyfolio<0.10,>=0.9->finrl==0.3.6)\n",
            "  Downloading pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting scipy>=0.14.0 (from pyfolio<0.10,>=0.9->finrl==0.3.6)\n",
            "  Downloading scipy-1.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting seaborn>=0.7.1 (from pyfolio<0.10,>=0.9->finrl==0.3.6)\n",
            "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting empyrical>=0.5.0 (from pyfolio<0.10,>=0.9->finrl==0.3.6)\n",
            "  Downloading empyrical-0.5.5.tar.gz (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.8/52.8 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting cvxpy<2.0.0,>=1.1.19 (from pyportfolioopt<2,>=1->finrl==0.3.6)\n",
            "  Downloading cvxpy-1.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.9 kB)\n",
            "Collecting numpy>=1.11.1 (from alpaca-trade-api<4,>=3->finrl==0.3.6)\n",
            "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting click>=7.0 (from ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.6)\n",
            "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting filelock (from ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.6)\n",
            "  Downloading filelock-3.15.4-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting jsonschema (from ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.6)\n",
            "  Downloading jsonschema-4.22.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting protobuf!=3.19.5,>=3.15.3 (from ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.6)\n",
            "  Downloading protobuf-5.27.2-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "Collecting aiosignal (from ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.6)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting frozenlist (from ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.6)\n",
            "  Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting tensorboardX>=1.9 (from ray[default,tune]<3,>=2->finrl==0.3.6)\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting pyarrow>=6.0.1 (from ray[default,tune]<3,>=2->finrl==0.3.6)\n",
            "  Downloading pyarrow-16.1.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting fsspec (from ray[default,tune]<3,>=2->finrl==0.3.6)\n",
            "  Downloading fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting aiohttp-cors (from ray[default,tune]<3,>=2->finrl==0.3.6)\n",
            "  Downloading aiohttp_cors-0.7.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting colorful (from ray[default,tune]<3,>=2->finrl==0.3.6)\n",
            "  Downloading colorful-0.5.6-py2.py3-none-any.whl.metadata (16 kB)\n",
            "Collecting py-spy>=0.2.0 (from ray[default,tune]<3,>=2->finrl==0.3.6)\n",
            "  Downloading py_spy-0.3.14-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (16 kB)\n",
            "Collecting opencensus (from ray[default,tune]<3,>=2->finrl==0.3.6)\n",
            "  Downloading opencensus-0.11.4-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Collecting pydantic!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3 (from ray[default,tune]<3,>=2->finrl==0.3.6)\n",
            "  Downloading pydantic-2.8.0-py3-none-any.whl.metadata (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.5/123.5 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting prometheus-client>=0.7.1 (from ray[default,tune]<3,>=2->finrl==0.3.6)\n",
            "  Downloading prometheus_client-0.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting smart-open (from ray[default,tune]<3,>=2->finrl==0.3.6)\n",
            "  Downloading smart_open-7.0.4-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting virtualenv!=20.21.1,>=20.0.24 (from ray[default,tune]<3,>=2->finrl==0.3.6)\n",
            "  Downloading virtualenv-20.26.3-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting grpcio>=1.42.0 (from ray[default,tune]<3,>=2->finrl==0.3.6)\n",
            "  Downloading grpcio-1.64.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting memray (from ray[default,tune]<3,>=2->finrl==0.3.6)\n",
            "  Downloading memray-1.13.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (19 kB)\n",
            "Collecting joblib>=1.2.0 (from scikit-learn<2,>=1->finrl==0.3.6)\n",
            "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting threadpoolctl>=3.1.0 (from scikit-learn<2,>=1->finrl==0.3.6)\n",
            "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting gymnasium<0.30,>=0.28.1 (from stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
            "  Downloading gymnasium-0.29.1-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting torch>=1.13 (from stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
            "  Downloading torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Collecting cloudpickle (from stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
            "  Downloading cloudpickle-3.0.0-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting opencv-python (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
            "  Downloading opencv_python-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Collecting pygame (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
            "  Downloading pygame-2.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting tensorboard>=2.9.1 (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
            "  Downloading tensorboard-2.17.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting psutil (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
            "  Downloading psutil-6.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/site-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (4.66.1)\n",
            "Collecting rich (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
            "  Downloading rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting shimmy~=1.3.0 (from shimmy[atari]~=1.3.0; extra == \"extra\"->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
            "  Downloading Shimmy-1.3.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting pillow (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
            "  Downloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
            "Collecting autorom~=0.6.1 (from autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
            "  Downloading AutoROM-0.6.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting psycopg2-binary<2.10,>=2.9 (from wrds<4,>=3->finrl==0.3.6)\n",
            "  Downloading psycopg2_binary-2.9.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
            "Collecting scipy>=0.14.0 (from pyfolio<0.10,>=0.9->finrl==0.3.6)\n",
            "  Downloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multitasking>=0.0.7 (from yfinance<0.3,>=0.2->finrl==0.3.6)\n",
            "  Downloading multitasking-0.0.11-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting lxml>=4.9.1 (from yfinance<0.3,>=0.2->finrl==0.3.6)\n",
            "  Downloading lxml-5.2.2-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.10/site-packages (from yfinance<0.3,>=0.2->finrl==0.3.6) (4.1.0)\n",
            "Collecting frozendict>=2.3.4 (from yfinance<0.3,>=0.2->finrl==0.3.6)\n",
            "  Downloading frozendict-2.4.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (23 kB)\n",
            "Collecting peewee>=3.16.2 (from yfinance<0.3,>=0.2->finrl==0.3.6)\n",
            "  Downloading peewee-3.17.5.tar.gz (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting beautifulsoup4>=4.11.1 (from yfinance<0.3,>=0.2->finrl==0.3.6)\n",
            "  Downloading beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting html5lib>=1.1 (from yfinance<0.3,>=0.2->finrl==0.3.6)\n",
            "  Downloading html5lib-1.1-py2.py3-none-any.whl.metadata (16 kB)\n",
            "Collecting gym (from elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl->finrl==0.3.6)\n",
            "  Downloading gym-0.26.2.tar.gz (721 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m721.7/721.7 kB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pycares>=4.0.0 (from aiodns>=1.1.1->ccxt<4,>=3->finrl==0.3.6)\n",
            "  Downloading pycares-4.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Collecting attrs>=17.3.0 (from aiohttp<4,>=3.8.3->alpaca-trade-api<4,>=3->finrl==0.3.6)\n",
            "  Downloading attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp<4,>=3.8.3->alpaca-trade-api<4,>=3->finrl==0.3.6)\n",
            "  Downloading multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Collecting async-timeout<5.0,>=4.0 (from aiohttp<4,>=3.8.3->alpaca-trade-api<4,>=3->finrl==0.3.6)\n",
            "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting AutoROM.accept-rom-license (from autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
            "  Downloading AutoROM.accept-rom-license-0.6.1.tar.gz (434 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.7/434.7 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting soupsieve>1.2 (from beautifulsoup4>=4.11.1->yfinance<0.3,>=0.2->finrl==0.3.6)\n",
            "  Downloading soupsieve-2.5-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/site-packages (from cryptography>=2.6.1->ccxt<4,>=3->finrl==0.3.6) (1.16.0)\n",
            "Collecting osqp>=0.6.2 (from cvxpy<2.0.0,>=1.1.19->pyportfolioopt<2,>=1->finrl==0.3.6)\n",
            "  Downloading osqp-0.6.7.post0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting ecos>=2 (from cvxpy<2.0.0,>=1.1.19->pyportfolioopt<2,>=1->finrl==0.3.6)\n",
            "  Downloading ecos-2.0.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.0 kB)\n",
            "Collecting clarabel>=0.5.0 (from cvxpy<2.0.0,>=1.1.19->pyportfolioopt<2,>=1->finrl==0.3.6)\n",
            "  Downloading clarabel-0.9.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
            "Collecting scs>=3.2.4.post1 (from cvxpy<2.0.0,>=1.1.19->pyportfolioopt<2,>=1->finrl==0.3.6)\n",
            "  Downloading scs-3.2.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting pandas-datareader>=0.2 (from empyrical>=0.5.0->pyfolio<0.10,>=0.9->finrl==0.3.6)\n",
            "  Downloading pandas_datareader-0.10.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting typing-extensions>=4.3.0 (from gymnasium<0.30,>=0.28.1->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
            "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium<0.30,>=0.28.1->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
            "  Using cached Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)\n",
            "Collecting webencodings (from html5lib>=1.1->yfinance<0.3,>=0.2->finrl==0.3.6)\n",
            "  Downloading webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting decorator (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6)\n",
            "  Downloading decorator-5.1.1-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting jedi>=0.16 (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting matplotlib-inline (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6)\n",
            "  Downloading matplotlib_inline-0.1.7-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting prompt-toolkit<3.1.0,>=3.0.41 (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6)\n",
            "  Downloading prompt_toolkit-3.0.47-py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting pygments>=2.4.0 (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6)\n",
            "  Downloading pygments-2.18.0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting stack-data (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6)\n",
            "  Downloading stack_data-0.6.3-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting traitlets>=5.13.0 (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6)\n",
            "  Downloading traitlets-5.14.3-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting exceptiongroup (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6)\n",
            "  Downloading exceptiongroup-1.2.1-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting pexpect>4.3 (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6)\n",
            "  Downloading pexpect-4.9.0-py2.py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting contourpy>=1.0.1 (from matplotlib>=1.4.0->pyfolio<0.10,>=0.9->finrl==0.3.6)\n",
            "  Downloading contourpy-1.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib>=1.4.0->pyfolio<0.10,>=0.9->finrl==0.3.6)\n",
            "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib>=1.4.0->pyfolio<0.10,>=0.9->finrl==0.3.6)\n",
            "  Downloading fonttools-4.53.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (162 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.2/162.2 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib>=1.4.0->pyfolio<0.10,>=0.9->finrl==0.3.6)\n",
            "  Downloading kiwisolver-1.4.5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.4 kB)\n",
            "Collecting pyparsing>=2.3.1 (from matplotlib>=1.4.0->pyfolio<0.10,>=0.9->finrl==0.3.6)\n",
            "  Downloading pyparsing-3.1.2-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting python-dateutil>=2.7 (from matplotlib>=1.4.0->pyfolio<0.10,>=0.9->finrl==0.3.6)\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting annotated-types>=0.4.0 (from pydantic!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3->ray[default,tune]<3,>=2->finrl==0.3.6)\n",
            "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pydantic-core==2.20.0 (from pydantic!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<3->ray[default,tune]<3,>=2->finrl==0.3.6)\n",
            "  Downloading pydantic_core-2.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests<3,>2->alpaca-trade-api<4,>=3->finrl==0.3.6) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests<3,>2->alpaca-trade-api<4,>=3->finrl==0.3.6) (3.6)\n",
            "Collecting ale-py~=0.8.1 (from shimmy[atari]~=1.3.0; extra == \"extra\"->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
            "  Downloading ale_py-0.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Collecting greenlet!=0.4.17 (from SQLAlchemy>=1.2.8->jqdatasdk<2,>=1->finrl==0.3.6)\n",
            "  Downloading greenlet-3.0.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting absl-py>=0.4 (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
            "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting markdown>=2.6.8 (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
            "  Downloading Markdown-3.6-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting protobuf!=3.19.5,>=3.15.3 (from ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.6)\n",
            "  Downloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
            "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting werkzeug>=1.0.1 (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
            "  Downloading werkzeug-3.0.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting ply<4.0,>=3.4 (from thriftpy2>=0.3.9->jqdatasdk<2,>=1->finrl==0.3.6)\n",
            "  Downloading ply-3.11-py2.py3-none-any.whl.metadata (844 bytes)\n",
            "Collecting sympy (from torch>=1.13->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
            "  Downloading sympy-1.12.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting networkx (from torch>=1.13->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
            "  Downloading networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting jinja2 (from torch>=1.13->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
            "  Downloading jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.13->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.13->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.13->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.13->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.13->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.13->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.13->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.13->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.13->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.13->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
            "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.13->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.3.1 (from torch>=1.13->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
            "  Downloading triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting distlib<1,>=0.3.7 (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<3,>=2->finrl==0.3.6)\n",
            "  Downloading distlib-0.3.8-py2.py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting gym-notices>=0.0.4 (from gym->elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl->finrl==0.3.6)\n",
            "  Downloading gym_notices-0.0.8-py3-none-any.whl.metadata (1.0 kB)\n",
            "Collecting box2d-py==2.3.5 (from gym[box2d]->elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl->finrl==0.3.6)\n",
            "  Downloading box2d-py-2.3.5.tar.gz (374 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.4/374.4 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pygame (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
            "  Downloading pygame-2.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.5 kB)\n",
            "Collecting swig==4.* (from gym[box2d]->elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl->finrl==0.3.6)\n",
            "  Downloading swig-4.2.1-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema->ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.6)\n",
            "  Downloading jsonschema_specifications-2023.12.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting referencing>=0.28.4 (from jsonschema->ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.6)\n",
            "  Downloading referencing-0.35.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting rpds-py>=0.7.1 (from jsonschema->ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.6)\n",
            "  Downloading rpds_py-0.18.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Collecting textual>=0.41.0 (from memray->ray[default,tune]<3,>=2->finrl==0.3.6)\n",
            "  Downloading textual-0.71.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting markdown-it-py>=2.2.0 (from rich->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
            "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting opencensus-context>=0.1.3 (from opencensus->ray[default,tune]<3,>=2->finrl==0.3.6)\n",
            "  Downloading opencensus_context-0.1.3-py2.py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting google-api-core<3.0.0,>=1.0.0 (from opencensus->ray[default,tune]<3,>=2->finrl==0.3.6)\n",
            "  Downloading google_api_core-2.19.1-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting wrapt (from smart-open->ray[default,tune]<3,>=2->finrl==0.3.6)\n",
            "  Downloading wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting importlib-resources (from ale-py~=0.8.1->shimmy[atari]~=1.3.0; extra == \"extra\"->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
            "  Downloading importlib_resources-6.4.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=2.6.1->ccxt<4,>=3->finrl==0.3.6) (2.21)\n",
            "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<3,>=2->finrl==0.3.6)\n",
            "  Downloading googleapis_common_protos-1.63.2-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<3,>=2->finrl==0.3.6)\n",
            "  Downloading proto_plus-1.24.0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting google-auth<3.0.dev0,>=2.14.1 (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<3,>=2->finrl==0.3.6)\n",
            "  Downloading google_auth-2.31.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting parso<0.9.0,>=0.8.3 (from jedi>=0.16->ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6)\n",
            "  Downloading parso-0.8.4-py2.py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch>=1.13->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
            "  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
            "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "INFO: pip is looking at multiple versions of osqp to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting osqp>=0.6.2 (from cvxpy<2.0.0,>=1.1.19->pyportfolioopt<2,>=1->finrl==0.3.6)\n",
            "  Downloading osqp-0.6.7-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "  Downloading osqp-0.6.6-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "  Downloading osqp-0.6.5-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "  Downloading osqp-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting qdldl (from osqp>=0.6.2->cvxpy<2.0.0,>=1.1.19->pyportfolioopt<2,>=1->finrl==0.3.6)\n",
            "  Downloading qdldl-0.1.7.post4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting ptyprocess>=0.5 (from pexpect>4.3->ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6)\n",
            "  Downloading ptyprocess-0.7.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting wcwidth (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6)\n",
            "  Downloading wcwidth-0.2.13-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Collecting executing>=1.2.0 (from stack-data->ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6)\n",
            "  Downloading executing-2.0.1-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting asttokens>=2.1.0 (from stack-data->ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6)\n",
            "  Downloading asttokens-2.4.1-py2.py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting pure-eval (from stack-data->ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6)\n",
            "  Downloading pure_eval-0.2.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting mpmath<1.4.0,>=1.1.0 (from sympy->torch>=1.13->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<3,>=2->finrl==0.3.6)\n",
            "  Downloading cachetools-5.3.3-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting pyasn1-modules>=0.2.1 (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<3,>=2->finrl==0.3.6)\n",
            "  Downloading pyasn1_modules-0.4.0-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting rsa<5,>=3.1.4 (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<3,>=2->finrl==0.3.6)\n",
            "  Downloading rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting mdit-py-plugins (from markdown-it-py[linkify,plugins]>=2.1.0->textual>=0.41.0->memray->ray[default,tune]<3,>=2->finrl==0.3.6)\n",
            "  Downloading mdit_py_plugins-0.4.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting linkify-it-py<3,>=1 (from markdown-it-py[linkify,plugins]>=2.1.0->textual>=0.41.0->memray->ray[default,tune]<3,>=2->finrl==0.3.6)\n",
            "  Downloading linkify_it_py-2.0.3-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting uc-micro-py (from linkify-it-py<3,>=1->markdown-it-py[linkify,plugins]>=2.1.0->textual>=0.41.0->memray->ray[default,tune]<3,>=2->finrl==0.3.6)\n",
            "  Downloading uc_micro_py-1.0.3-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<3,>=2->finrl==0.3.6)\n",
            "  Downloading pyasn1-0.6.0-py2.py3-none-any.whl.metadata (8.3 kB)\n",
            "Downloading alpaca_trade_api-3.2.0-py3-none-any.whl (34 kB)\n",
            "Downloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading msgpack-1.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (323 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.7/323.7 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (705 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m705.5/705.5 kB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ccxt-3.1.60-py2.py3-none-any.whl (4.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading exchange_calendars-4.5.5-py3-none-any.whl (196 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.1/196.1 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jqdatasdk-1.9.5-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyportfolioopt-1.5.5-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.9/61.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ray-2.31.0-cp310-cp310-manylinux2014_x86_64.whl (66.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.2/66.2 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_learn-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m79.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading stable_baselines3-2.4.0a4-py3-none-any.whl (182 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.3/182.3 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading stockstats-0.5.4-py2.py3-none-any.whl (21 kB)\n",
            "Downloading wrds-3.2.0-py3-none-any.whl (13 kB)\n",
            "Downloading yfinance-0.2.40-py2.py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiodns-3.2.0-py3-none-any.whl (5.7 kB)\n",
            "Downloading aiohttp-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Downloading AutoROM-0.6.1-py3-none-any.whl (9.4 kB)\n",
            "Downloading beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.9/147.9 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached click-8.1.7-py3-none-any.whl (97 kB)\n",
            "Downloading cryptography-42.0.8-cp39-abi3-manylinux_2_28_x86_64.whl (3.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m74.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cvxpy-1.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading frozendict-2.4.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (117 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.3/117.3 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (239 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.5/239.5 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading grpcio-1.64.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cloudpickle-3.0.0-py3-none-any.whl (20 kB)\n",
            "Downloading html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.2/112.2 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ipython-8.26.0-py3-none-any.whl (817 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m817.9/817.9 kB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lxml-5.2.2-cp310-cp310-manylinux_2_28_x86_64.whl (5.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading matplotlib-3.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multitasking-0.0.11-py3-none-any.whl (8.5 kB)\n",
            "Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m65.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading prometheus_client-0.20.0-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading psycopg2_binary-2.9.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading py_spy-0.3.14-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-16.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (40.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic-2.8.0-py3-none-any.whl (423 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m423.1/423.1 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_core-2.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m67.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyMySQL-1.1.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.0/45.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m505.5/505.5 kB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.4/38.4 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Shimmy-1.3.0-py3-none-any.whl (37 kB)\n",
            "Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading SQLAlchemy-2.0.31-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m72.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.17.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m69.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
            "Downloading torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m945.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.4/345.4 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading urllib3-1.26.19-py2.py3-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.9/143.9 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading virtualenv-20.26.3-py3-none-any.whl (5.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filelock-3.15.4-py3-none-any.whl (16 kB)\n",
            "Downloading websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-10.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (106 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.8/106.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.6/301.6 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\n",
            "Downloading colorful-0.5.6-py2.py3-none-any.whl (201 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.4/201.4 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.6/177.6 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pygame-2.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading swig-4.2.1-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonschema-4.22.0-py3-none-any.whl (88 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading korean_lunar_calendar-0.3.1-py3-none-any.whl (9.0 kB)\n",
            "Downloading memray-1.13.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rich-13.7.1-py3-none-any.whl (240 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.7/240.7 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencensus-0.11.4-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_python-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (62.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading psutil-6.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (290 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.5/290.5 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyluach-2.2.0-py3-none-any.whl (25 kB)\n",
            "Downloading smart_open-7.0.4-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading toolz-0.12.1-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.1/56.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ale_py-0.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m58.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
            "Downloading attrs-23.2.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading clarabel-0.9.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading contourpy-1.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (305 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m305.2/305.2 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Downloading distlib-0.3.8-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.9/468.9 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ecos-2.0.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (218 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m218.9/218.9 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Downloading fonttools-4.53.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m83.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_api_core-2.19.1-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading greenlet-3.0.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (616 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m616.0/616.0 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gym_notices-0.0.8-py3-none-any.whl (3.0 kB)\n",
            "Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.3/133.3 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonschema_specifications-2023.12.1-py3-none-any.whl (18 kB)\n",
            "Downloading kiwisolver-1.4.5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m64.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Markdown-3.6-py3-none-any.whl (105 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.3/124.3 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\n",
            "Downloading osqp-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (298 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.0/299.0 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas_datareader-0.10.0-py3-none-any.whl (109 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.5/109.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pexpect-4.9.0-py2.py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.8/63.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ply-3.11-py2.py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading prompt_toolkit-3.0.47-py3-none-any.whl (386 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.4/386.4 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycares-4.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.7/288.7 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pygments-2.18.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyparsing-3.1.2-py3-none-any.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.2/103.2 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading referencing-0.35.1-py3-none-any.whl (26 kB)\n",
            "Downloading rpds_py-0.18.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scs-3.2.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m72.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading soupsieve-2.5-py3-none-any.whl (36 kB)\n",
            "Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m85.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading textual-0.71.0-py3-none-any.whl (561 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m561.2/561.2 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading traitlets-5.14.3-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
            "Downloading werkzeug-3.0.3-py3-none-any.whl (227 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.3/227.3 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
            "Downloading exceptiongroup-1.2.1-py3-none-any.whl (16 kB)\n",
            "Downloading matplotlib_inline-0.1.7-py3-none-any.whl (9.9 kB)\n",
            "Downloading networkx-3.3-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading stack_data-0.6.3-py3-none-any.whl (24 kB)\n",
            "Downloading sympy-1.12.1-py3-none-any.whl (5.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m81.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
            "Downloading wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (80 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.3/80.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading asttokens-2.4.1-py2.py3-none-any.whl (27 kB)\n",
            "Downloading executing-2.0.1-py2.py3-none-any.whl (24 kB)\n",
            "Downloading google_auth-2.31.0-py2.py3-none-any.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.6/194.6 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading googleapis_common_protos-1.63.2-py2.py3-none-any.whl (220 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.0/220.0 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading parso-0.8.4-py2.py3-none-any.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.7/103.7 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading proto_plus-1.24.0-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\n",
            "Downloading importlib_resources-6.4.0-py3-none-any.whl (38 kB)\n",
            "Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pure_eval-0.2.2-py3-none-any.whl (11 kB)\n",
            "Downloading qdldl-0.1.7.post4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wcwidth-0.2.13-py2.py3-none-any.whl (34 kB)\n",
            "Downloading cachetools-5.3.3-py3-none-any.whl (9.3 kB)\n",
            "Downloading linkify_it_py-2.0.3-py3-none-any.whl (19 kB)\n",
            "Downloading pyasn1_modules-0.4.0-py3-none-any.whl (181 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.2/181.2 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rsa-4.9-py3-none-any.whl (34 kB)\n",
            "Downloading mdit_py_plugins-0.4.1-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.8/54.8 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyasn1-0.6.0-py2.py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.3/85.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uc_micro_py-1.0.3-py3-none-any.whl (6.2 kB)\n",
            "Building wheels for collected packages: finrl, pyfolio, elegantrl, empyrical, peewee, thriftpy2, gym, box2d-py, AutoROM.accept-rom-license\n",
            "  Building wheel for finrl (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for finrl: filename=finrl-0.3.6-py3-none-any.whl size=4691622 sha256=ec1e22ebb6384192ec476268c112e1d59c43fc1e1a27e8446871e5000599d62d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-kw236dqg/wheels/72/3b/1a/0fc805a8cc65ecd5bfe4f74a3c586b6075678b8ba53fd8f749\n",
            "  Building wheel for pyfolio (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyfolio: filename=pyfolio-0.9.2-py3-none-any.whl size=88650 sha256=0356a0a1dec1a9428754b74244cdf3005405575db066017d8748c48344ac40b6\n",
            "  Stored in directory: /root/.cache/pip/wheels/71/38/bc/e53700cfd8b0ad6b539d2fbaaf060ed8a299e7622a5b86ef42\n",
            "  Building wheel for elegantrl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for elegantrl: filename=ElegantRL-0.3.7-py3-none-any.whl size=197533 sha256=da3f244ce338dae59a8ff09dec0e63cd426f1776b57e9dea442fe54b7be340ff\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-kw236dqg/wheels/c0/51/a5/b05f165548221bc570f7223babd33e2992fa873cdcebe2d229\n",
            "  Building wheel for empyrical (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for empyrical: filename=empyrical-0.5.5-py3-none-any.whl size=39754 sha256=bc7b19c680314dd94673f12bc1b0d25399206b1c63dd11e4a2d04de2c0d2f495\n",
            "  Stored in directory: /root/.cache/pip/wheels/0e/2e/f2/d6d2d9a1eb8fbbd9949bb5d4c00f753e3b74e5bd7ed10b1d36\n",
            "  Building wheel for peewee (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for peewee: filename=peewee-3.17.5-cp310-cp310-linux_x86_64.whl size=275467 sha256=c53fe3d0b8892f4c58c393cb697e8ca637e1585b65141fa668736664ba758ed7\n",
            "  Stored in directory: /root/.cache/pip/wheels/06/80/9b/98db0d58349a2f5c09f8406789ade4270762f97b7d26f2fa22\n",
            "  Building wheel for thriftpy2 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for thriftpy2: filename=thriftpy2-0.5.1-cp310-cp310-linux_x86_64.whl size=841069 sha256=2b5a11ee0841de36213e6ac755157b2f0de54f3e1b3858af09fd5c9587dd8b01\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/3c/25/099e035974c7596c4f727ed33f1d7ec72ecfd551dc2ed8f52a\n",
            "  Building wheel for gym (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.26.2-py3-none-any.whl size=827625 sha256=e339834b6b4bb94fe0e65e805be3d4c7d384dcd903c8466384144f9338d1a3f9\n",
            "  Stored in directory: /root/.cache/pip/wheels/b9/22/6d/3e7b32d98451b4cd9d12417052affbeeeea012955d437da1da\n",
            "  Building wheel for box2d-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for box2d-py: filename=box2d_py-2.3.5-cp310-cp310-linux_x86_64.whl size=495617 sha256=bc3de4bec2fd8befcd4cf21adac753c9332c2fa248156ec4eba9152523887acd\n",
            "  Stored in directory: /root/.cache/pip/wheels/db/8f/6a/eaaadf056fba10a98d986f6dce954e6201ba3126926fc5ad9e\n",
            "  Building wheel for AutoROM.accept-rom-license (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for AutoROM.accept-rom-license: filename=AutoROM.accept_rom_license-0.6.1-py3-none-any.whl size=446661 sha256=29a36b207b4a28b1e194a471a6568ae6ea76022171a83e0f2e19ef0eadc6215f\n",
            "  Stored in directory: /root/.cache/pip/wheels/6b/1b/ef/a43ff1a2f1736d5711faa1ba4c1f61be1131b8899e6a057811\n",
            "Successfully built finrl pyfolio elegantrl empyrical peewee thriftpy2 gym box2d-py AutoROM.accept-rom-license\n",
            "Installing collected packages: webencodings, wcwidth, swig, pytz, py-spy, pure-eval, ptyprocess, ply, peewee, opencensus-context, multitasking, msgpack, mpmath, korean-lunar-calendar, gym-notices, farama-notifications, distlib, colorful, box2d-py, wrapt, websockets, websocket-client, urllib3, uc-micro-py, tzdata, typing-extensions, traitlets, toolz, threadpoolctl, tensorboard-data-server, sympy, soupsieve, six, rpds-py, PyYAML, pyparsing, pymysql, pyluach, pygments, pygame, pyasn1, psycopg2-binary, psutil, protobuf, prompt-toolkit, prometheus-client, pillow, pexpect, parso, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, multidict, mdurl, MarkupSafe, markdown, lxml, kiwisolver, joblib, importlib-resources, grpcio, greenlet, fsspec, frozenlist, frozendict, fonttools, filelock, executing, exceptiongroup, deprecation, decorator, cycler, cloudpickle, click, cachetools, attrs, async-timeout, annotated-types, absl-py, yarl, werkzeug, virtualenv, triton, thriftpy2, tensorboardX, SQLAlchemy, smart-open, scipy, rsa, referencing, python-dateutil, pydantic-core, pycares, pyasn1-modules, pyarrow, proto-plus, opencv-python, nvidia-cusparse-cu12, nvidia-cudnn-cu12, matplotlib-inline, markdown-it-py, linkify-it-py, jinja2, jedi, html5lib, gymnasium, gym, googleapis-common-protos, cryptography, contourpy, beautifulsoup4, asttokens, ale-py, aiosignal, tensorboard, stack-data, shimmy, scs, scikit-learn, rich, qdldl, pydantic, pandas, nvidia-cusolver-cu12, mdit-py-plugins, matplotlib, jsonschema-specifications, google-auth, ecos, clarabel, AutoROM.accept-rom-license, autorom, aiohttp, aiodns, yfinance, wrds, torch, stockstats, seaborn, pandas-datareader, osqp, jsonschema, jqdatasdk, ipython, google-api-core, exchange-calendars, ccxt, alpaca-trade-api, aiohttp-cors, textual, stable-baselines3, ray, opencensus, empyrical, elegantrl, cvxpy, pyportfolioopt, pyfolio, memray, finrl\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.1.0\n",
            "    Uninstalling urllib3-2.1.0:\n",
            "      Successfully uninstalled urllib3-2.1.0\n",
            "Successfully installed AutoROM.accept-rom-license-0.6.1 MarkupSafe-2.1.5 PyYAML-6.0.1 SQLAlchemy-2.0.31 absl-py-2.1.0 aiodns-3.2.0 aiohttp-3.9.5 aiohttp-cors-0.7.0 aiosignal-1.3.1 ale-py-0.8.1 alpaca-trade-api-3.2.0 annotated-types-0.7.0 asttokens-2.4.1 async-timeout-4.0.3 attrs-23.2.0 autorom-0.6.1 beautifulsoup4-4.12.3 box2d-py-2.3.5 cachetools-5.3.3 ccxt-3.1.60 clarabel-0.9.0 click-8.1.7 cloudpickle-3.0.0 colorful-0.5.6 contourpy-1.2.1 cryptography-42.0.8 cvxpy-1.5.2 cycler-0.12.1 decorator-5.1.1 deprecation-2.1.0 distlib-0.3.8 ecos-2.0.14 elegantrl-0.3.7 empyrical-0.5.5 exceptiongroup-1.2.1 exchange-calendars-4.5.5 executing-2.0.1 farama-notifications-0.0.4 filelock-3.15.4 finrl-0.3.6 fonttools-4.53.0 frozendict-2.4.4 frozenlist-1.4.1 fsspec-2024.6.1 google-api-core-2.19.1 google-auth-2.31.0 googleapis-common-protos-1.63.2 greenlet-3.0.3 grpcio-1.64.1 gym-0.26.2 gym-notices-0.0.8 gymnasium-0.29.1 html5lib-1.1 importlib-resources-6.4.0 ipython-8.26.0 jedi-0.19.1 jinja2-3.1.4 joblib-1.4.2 jqdatasdk-1.9.5 jsonschema-4.22.0 jsonschema-specifications-2023.12.1 kiwisolver-1.4.5 korean-lunar-calendar-0.3.1 linkify-it-py-2.0.3 lxml-5.2.2 markdown-3.6 markdown-it-py-3.0.0 matplotlib-3.9.0 matplotlib-inline-0.1.7 mdit-py-plugins-0.4.1 mdurl-0.1.2 memray-1.13.3 mpmath-1.3.0 msgpack-1.0.3 multidict-6.0.5 multitasking-0.0.11 networkx-3.3 numpy-1.26.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 opencensus-0.11.4 opencensus-context-0.1.3 opencv-python-4.10.0.84 osqp-0.6.4 pandas-2.2.2 pandas-datareader-0.10.0 parso-0.8.4 peewee-3.17.5 pexpect-4.9.0 pillow-10.4.0 ply-3.11 prometheus-client-0.20.0 prompt-toolkit-3.0.47 proto-plus-1.24.0 protobuf-4.25.3 psutil-6.0.0 psycopg2-binary-2.9.9 ptyprocess-0.7.0 pure-eval-0.2.2 py-spy-0.3.14 pyarrow-16.1.0 pyasn1-0.6.0 pyasn1-modules-0.4.0 pycares-4.4.0 pydantic-2.8.0 pydantic-core-2.20.0 pyfolio-0.9.2 pygame-2.1.0 pygments-2.18.0 pyluach-2.2.0 pymysql-1.1.1 pyparsing-3.1.2 pyportfolioopt-1.5.5 python-dateutil-2.9.0.post0 pytz-2024.1 qdldl-0.1.7.post4 ray-2.31.0 referencing-0.35.1 rich-13.7.1 rpds-py-0.18.1 rsa-4.9 scikit-learn-1.5.1 scipy-1.12.0 scs-3.2.5 seaborn-0.13.2 shimmy-1.3.0 six-1.16.0 smart-open-7.0.4 soupsieve-2.5 stable-baselines3-2.4.0a4 stack-data-0.6.3 stockstats-0.5.4 swig-4.2.1 sympy-1.12.1 tensorboard-2.17.0 tensorboard-data-server-0.7.2 tensorboardX-2.6.2.2 textual-0.71.0 threadpoolctl-3.5.0 thriftpy2-0.5.1 toolz-0.12.1 torch-2.3.1 traitlets-5.14.3 triton-2.3.1 typing-extensions-4.12.2 tzdata-2024.1 uc-micro-py-1.0.3 urllib3-1.26.19 virtualenv-20.26.3 wcwidth-0.2.13 webencodings-0.5.1 websocket-client-1.8.0 websockets-10.4 werkzeug-3.0.3 wrapt-1.16.0 wrds-3.2.0 yarl-1.9.4 yfinance-0.2.40\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "cycler",
                  "google",
                  "kiwisolver",
                  "matplotlib_inline",
                  "pexpect",
                  "prompt_toolkit",
                  "six",
                  "wcwidth"
                ]
              },
              "id": "1a94e55504d9475eae5c5ecf2c714382"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "## install finrl library\n",
        "!pip install wrds\n",
        "!pip install swig\n",
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()\n",
        "!apt-get update -y -qq && apt-get install -y -qq cmake libopenmpi-dev python3-dev zlib1g-dev libgl1-mesa-glx swig\n",
        "!pip install git+https://github.com/AI4Finance-Foundation/FinRL.git\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNoUkH4rnmJc",
        "outputId": "7423854a-6b2c-4237-d175-4b0eb97ecbac"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "absl-py==2.1.0\n",
            "aiodns==3.2.0\n",
            "aiohttp==3.9.5\n",
            "aiohttp-cors==0.7.0\n",
            "aiosignal==1.3.1\n",
            "ale-py==0.8.1\n",
            "alpaca-trade-api==3.2.0\n",
            "annotated-types==0.7.0\n",
            "archspec @ file:///home/conda/feedstock_root/build_artifacts/archspec_1699370045702/work\n",
            "asttokens==2.4.1\n",
            "async-timeout==4.0.3\n",
            "attrs==23.2.0\n",
            "AutoROM==0.6.1\n",
            "AutoROM.accept-rom-license==0.6.1\n",
            "beautifulsoup4==4.12.3\n",
            "boltons @ file:///home/conda/feedstock_root/build_artifacts/boltons_1703154663129/work\n",
            "box2d-py==2.3.5\n",
            "Brotli @ file:///home/conda/feedstock_root/build_artifacts/brotli-split_1695989787169/work\n",
            "cachetools==5.3.3\n",
            "ccxt==3.1.60\n",
            "certifi @ file:///home/conda/feedstock_root/build_artifacts/certifi_1700303426725/work/certifi\n",
            "cffi @ file:///home/conda/feedstock_root/build_artifacts/cffi_1696001684923/work\n",
            "charset-normalizer @ file:///home/conda/feedstock_root/build_artifacts/charset-normalizer_1698833585322/work\n",
            "clarabel==0.9.0\n",
            "click==8.1.7\n",
            "cloudpickle==3.0.0\n",
            "colorama @ file:///home/conda/feedstock_root/build_artifacts/colorama_1666700638685/work\n",
            "colorful==0.5.6\n",
            "conda @ file:///home/conda/feedstock_root/build_artifacts/conda_1701731572133/work\n",
            "conda-libmamba-solver @ file:///home/conda/feedstock_root/build_artifacts/conda-libmamba-solver_1702406360642/work/src\n",
            "conda-package-handling @ file:///home/conda/feedstock_root/build_artifacts/conda-package-handling_1691048088238/work\n",
            "conda_package_streaming @ file:///home/conda/feedstock_root/build_artifacts/conda-package-streaming_1691009212940/work\n",
            "contourpy==1.2.1\n",
            "cryptography==42.0.8\n",
            "cvxpy==1.5.2\n",
            "cycler==0.12.1\n",
            "decorator==5.1.1\n",
            "deprecation==2.1.0\n",
            "distlib==0.3.8\n",
            "distro @ file:///home/conda/feedstock_root/build_artifacts/distro_1675116244235/work\n",
            "ecos==2.0.14\n",
            "ElegantRL @ git+https://github.com/AI4Finance-Foundation/ElegantRL.git@6ead2cbd17e4ecd3942fc8a394719db1515cf13f\n",
            "empyrical==0.5.5\n",
            "exceptiongroup==1.2.1\n",
            "exchange_calendars==4.5.5\n",
            "executing==2.0.1\n",
            "Farama-Notifications==0.0.4\n",
            "filelock==3.15.4\n",
            "finrl @ git+https://github.com/AI4Finance-Foundation/FinRL.git@c7c0429a14f94fd2a460558bb49240e184f8d32d\n",
            "fonttools==4.53.0\n",
            "frozendict==2.4.4\n",
            "frozenlist==1.4.1\n",
            "fsspec==2024.6.1\n",
            "google-api-core==2.19.1\n",
            "google-auth==2.31.0\n",
            "googleapis-common-protos==1.63.2\n",
            "greenlet==3.0.3\n",
            "grpcio==1.64.1\n",
            "gym==0.26.2\n",
            "gym-notices==0.0.8\n",
            "gymnasium==0.29.1\n",
            "html5lib==1.1\n",
            "idna @ file:///home/conda/feedstock_root/build_artifacts/idna_1701026962277/work\n",
            "importlib_resources==6.4.0\n",
            "ipython==8.26.0\n",
            "jedi==0.19.1\n",
            "Jinja2==3.1.4\n",
            "joblib==1.4.2\n",
            "jqdatasdk==1.9.5\n",
            "jsonpatch @ file:///home/conda/feedstock_root/build_artifacts/jsonpatch_1695536281965/work\n",
            "jsonpointer @ file:///home/conda/feedstock_root/build_artifacts/jsonpointer_1695397238043/work\n",
            "jsonschema==4.22.0\n",
            "jsonschema-specifications==2023.12.1\n",
            "kiwisolver==1.4.5\n",
            "korean-lunar-calendar==0.3.1\n",
            "libmambapy @ file:///home/conda/feedstock_root/build_artifacts/mamba-split_1702310393080/work/libmambapy\n",
            "linkify-it-py==2.0.3\n",
            "lxml==5.2.2\n",
            "mamba @ file:///home/conda/feedstock_root/build_artifacts/mamba-split_1702310393080/work/mamba\n",
            "Markdown==3.6\n",
            "markdown-it-py==3.0.0\n",
            "MarkupSafe==2.1.5\n",
            "matplotlib==3.9.0\n",
            "matplotlib-inline==0.1.7\n",
            "mdit-py-plugins==0.4.1\n",
            "mdurl==0.1.2\n",
            "memray==1.13.3\n",
            "menuinst @ file:///home/conda/feedstock_root/build_artifacts/menuinst_1702317041727/work\n",
            "mpmath==1.3.0\n",
            "msgpack==1.0.3\n",
            "multidict==6.0.5\n",
            "multitasking==0.0.11\n",
            "networkx==3.3\n",
            "numpy==1.26.4\n",
            "nvidia-cublas-cu12==12.1.3.1\n",
            "nvidia-cuda-cupti-cu12==12.1.105\n",
            "nvidia-cuda-nvrtc-cu12==12.1.105\n",
            "nvidia-cuda-runtime-cu12==12.1.105\n",
            "nvidia-cudnn-cu12==8.9.2.26\n",
            "nvidia-cufft-cu12==11.0.2.54\n",
            "nvidia-curand-cu12==10.3.2.106\n",
            "nvidia-cusolver-cu12==11.4.5.107\n",
            "nvidia-cusparse-cu12==12.1.0.106\n",
            "nvidia-nccl-cu12==2.20.5\n",
            "nvidia-nvjitlink-cu12==12.5.82\n",
            "nvidia-nvtx-cu12==12.1.105\n",
            "opencensus==0.11.4\n",
            "opencensus-context==0.1.3\n",
            "opencv-python==4.10.0.84\n",
            "osqp==0.6.4\n",
            "packaging @ file:///home/conda/feedstock_root/build_artifacts/packaging_1696202382185/work\n",
            "pandas==2.2.2\n",
            "pandas-datareader==0.10.0\n",
            "parso==0.8.4\n",
            "peewee==3.17.5\n",
            "pexpect==4.9.0\n",
            "pillow==10.4.0\n",
            "platformdirs @ file:///home/conda/feedstock_root/build_artifacts/platformdirs_1701708255999/work\n",
            "pluggy @ file:///home/conda/feedstock_root/build_artifacts/pluggy_1693086607691/work\n",
            "ply==3.11\n",
            "prometheus_client==0.20.0\n",
            "prompt_toolkit==3.0.47\n",
            "proto-plus==1.24.0\n",
            "protobuf==4.25.3\n",
            "psutil==6.0.0\n",
            "psycopg2-binary==2.9.9\n",
            "ptyprocess==0.7.0\n",
            "pure-eval==0.2.2\n",
            "py-spy==0.3.14\n",
            "pyarrow==16.1.0\n",
            "pyasn1==0.6.0\n",
            "pyasn1_modules==0.4.0\n",
            "pycares==4.4.0\n",
            "pycosat @ file:///home/conda/feedstock_root/build_artifacts/pycosat_1696355758174/work\n",
            "pycparser @ file:///home/conda/feedstock_root/build_artifacts/pycparser_1636257122734/work\n",
            "pydantic==2.8.0\n",
            "pydantic_core==2.20.0\n",
            "pyfolio==0.9.2\n",
            "pygame==2.1.0\n",
            "Pygments==2.18.0\n",
            "pyluach==2.2.0\n",
            "PyMySQL==1.1.1\n",
            "pyparsing==3.1.2\n",
            "pyportfolioopt==1.5.5\n",
            "PySocks @ file:///home/conda/feedstock_root/build_artifacts/pysocks_1661604839144/work\n",
            "python-dateutil==2.9.0.post0\n",
            "pytz==2024.1\n",
            "PyYAML==6.0.1\n",
            "qdldl==0.1.7.post4\n",
            "ray==2.31.0\n",
            "referencing==0.35.1\n",
            "requests @ file:///home/conda/feedstock_root/build_artifacts/requests_1684774241324/work\n",
            "rich==13.7.1\n",
            "rpds-py==0.18.1\n",
            "rsa==4.9\n",
            "ruamel.yaml @ file:///home/conda/feedstock_root/build_artifacts/ruamel.yaml_1699007337104/work\n",
            "ruamel.yaml.clib @ file:///home/conda/feedstock_root/build_artifacts/ruamel.yaml.clib_1695996839082/work\n",
            "scikit-learn==1.5.1\n",
            "scipy==1.12.0\n",
            "scs==3.2.5\n",
            "seaborn==0.13.2\n",
            "Shimmy==1.3.0\n",
            "six==1.16.0\n",
            "smart-open==7.0.4\n",
            "soupsieve==2.5\n",
            "SQLAlchemy==2.0.31\n",
            "stable_baselines3==2.4.0a4\n",
            "stack-data==0.6.3\n",
            "stockstats==0.5.4\n",
            "swig==4.2.1\n",
            "sympy==1.12.1\n",
            "tensorboard==2.17.0\n",
            "tensorboard-data-server==0.7.2\n",
            "tensorboardX==2.6.2.2\n",
            "textual==0.71.0\n",
            "threadpoolctl==3.5.0\n",
            "thriftpy2==0.5.1\n",
            "toolz==0.12.1\n",
            "torch==2.3.1\n",
            "tqdm @ file:///home/conda/feedstock_root/build_artifacts/tqdm_1691671248568/work\n",
            "traitlets==5.14.3\n",
            "triton==2.3.1\n",
            "truststore @ file:///home/conda/feedstock_root/build_artifacts/truststore_1694154605758/work\n",
            "typing_extensions==4.12.2\n",
            "tzdata==2024.1\n",
            "uc-micro-py==1.0.3\n",
            "urllib3==1.26.19\n",
            "virtualenv==20.26.3\n",
            "wcwidth==0.2.13\n",
            "webencodings==0.5.1\n",
            "websocket-client==1.8.0\n",
            "websockets==10.4\n",
            "Werkzeug==3.0.3\n",
            "wrapt==1.16.0\n",
            "wrds==3.2.0\n",
            "yarl==1.9.4\n",
            "yfinance==0.2.40\n",
            "zstandard==0.22.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rwy7V72-8YY"
      },
      "source": [
        "## Get the API Keys Ready"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Z6qlLXY-fA2"
      },
      "outputs": [],
      "source": [
        "API_KEY = \"PKDUUBZUHLJGBMDBFA1Z\"\n",
        "API_SECRET = \"w8ksNcXRNrBxdL7HhsXssLyxsUXxqNXeg88scceO\"\n",
        "API_BASE_URL = 'https://paper-api.alpaca.markets'\n",
        "data_url = 'wss://data.alpaca.markets'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--6Kx8I21erH"
      },
      "source": [
        "## Import related modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "H7I7zsyYfoLJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "37317f9d-c539-4ab5-de9f-31e534c11717"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'finrl'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-f59e467f01c2>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfinrl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_tickers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDOW_30_TICKER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfinrl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mINDICATORS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfinrl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv_stock_trading\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv_stocktrading_np\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStockTradingEnv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfinrl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv_stock_trading\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv_stock_papertrading\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAlpacaPaperTrading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfinrl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_processor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataProcessor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'finrl'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "from finrl.config_tickers import DOW_30_TICKER\n",
        "from finrl.config import INDICATORS\n",
        "from finrl.meta.env_stock_trading.env_stocktrading_np import StockTradingEnv\n",
        "from finrl.meta.env_stock_trading.env_stock_papertrading import AlpacaPaperTrading\n",
        "from finrl.meta.data_processor import DataProcessor\n",
        "from finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EVJIQUR6_fu"
      },
      "source": [
        "## PPO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-EYx40S84tzo"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import gym\n",
        "import numpy as np\n",
        "import numpy.random as rd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from copy import deepcopy\n",
        "from torch import Tensor\n",
        "from torch.distributions.normal import Normal\n",
        "\n",
        "\n",
        "class ActorPPO(nn.Module):\n",
        "    def __init__(self, dims: [int], state_dim: int, action_dim: int):\n",
        "        super().__init__()\n",
        "        self.net = build_mlp(dims=[state_dim, *dims, action_dim])\n",
        "        self.action_std_log = nn.Parameter(torch.zeros((1, action_dim)), requires_grad=True)  # trainable parameter\n",
        "\n",
        "    def forward(self, state: Tensor) -> Tensor:\n",
        "        return self.net(state).tanh()  # action.tanh()\n",
        "\n",
        "    def get_action(self, state: Tensor) -> (Tensor, Tensor):  # for exploration\n",
        "        action_avg = self.net(state)\n",
        "        action_std = self.action_std_log.exp()\n",
        "\n",
        "        dist = Normal(action_avg, action_std)\n",
        "        action = dist.sample()\n",
        "        logprob = dist.log_prob(action).sum(1)\n",
        "        return action, logprob\n",
        "\n",
        "    def get_logprob_entropy(self, state: Tensor, action: Tensor) -> (Tensor, Tensor):\n",
        "        action_avg = self.net(state)\n",
        "        action_std = self.action_std_log.exp()\n",
        "\n",
        "        dist = Normal(action_avg, action_std)\n",
        "        logprob = dist.log_prob(action).sum(1)\n",
        "        entropy = dist.entropy().sum(1)\n",
        "        return logprob, entropy\n",
        "\n",
        "    @staticmethod\n",
        "    def convert_action_for_env(action: Tensor) -> Tensor:\n",
        "        return action.tanh()\n",
        "\n",
        "\n",
        "class CriticPPO(nn.Module):\n",
        "    def __init__(self, dims: [int], state_dim: int, _action_dim: int):\n",
        "        super().__init__()\n",
        "        self.net = build_mlp(dims=[state_dim, *dims, 1])\n",
        "\n",
        "    def forward(self, state: Tensor) -> Tensor:\n",
        "        return self.net(state)  # advantage value\n",
        "\n",
        "\n",
        "def build_mlp(dims: [int]) -> nn.Sequential:  # MLP (MultiLayer Perceptron)\n",
        "    net_list = []\n",
        "    for i in range(len(dims) - 1):\n",
        "        net_list.extend([nn.Linear(dims[i], dims[i + 1]), nn.ReLU()])\n",
        "    del net_list[-1]  # remove the activation of output layer\n",
        "    return nn.Sequential(*net_list)\n",
        "\n",
        "\n",
        "class Config:\n",
        "    def __init__(self, agent_class=None, env_class=None, env_args=None):\n",
        "        self.env_class = env_class  # env = env_class(**env_args)\n",
        "        self.env_args = env_args  # env = env_class(**env_args)\n",
        "\n",
        "        if env_args is None:  # dummy env_args\n",
        "            env_args = {'env_name': None, 'state_dim': None, 'action_dim': None, 'if_discrete': None}\n",
        "        self.env_name = env_args['env_name']  # the name of environment. Be used to set 'cwd'.\n",
        "        self.state_dim = env_args['state_dim']  # vector dimension (feature number) of state\n",
        "        self.action_dim = env_args['action_dim']  # vector dimension (feature number) of action\n",
        "        self.if_discrete = env_args['if_discrete']  # discrete or continuous action space\n",
        "\n",
        "        self.agent_class = agent_class  # agent = agent_class(...)\n",
        "\n",
        "        '''Arguments for reward shaping'''\n",
        "        self.gamma = 0.99  # discount factor of future rewards\n",
        "        self.reward_scale = 1.0  # an approximate target reward usually be closed to 256\n",
        "\n",
        "        '''Arguments for training'''\n",
        "        self.gpu_id = int(0)  # `int` means the ID of single GPU, -1 means CPU\n",
        "        self.net_dims = (64, 32)  # the middle layer dimension of MLP (MultiLayer Perceptron)\n",
        "        self.learning_rate = 6e-5  # 2 ** -14 ~= 6e-5\n",
        "        self.soft_update_tau = 5e-3  # 2 ** -8 ~= 5e-3\n",
        "        self.batch_size = int(128)  # num of transitions sampled from replay buffer.\n",
        "        self.horizon_len = int(2000)  # collect horizon_len step while exploring, then update network\n",
        "        self.buffer_size = None  # ReplayBuffer size. Empty the ReplayBuffer for on-policy.\n",
        "        self.repeat_times = 8.0  # repeatedly update network using ReplayBuffer to keep critic's loss small\n",
        "\n",
        "        '''Arguments for evaluate'''\n",
        "        self.cwd = None  # current working directory to save model. None means set automatically\n",
        "        self.break_step = +np.inf  # break training if 'total_step > break_step'\n",
        "        self.eval_times = int(32)  # number of times that get episodic cumulative return\n",
        "        self.eval_per_step = int(2e4)  # evaluate the agent per training steps\n",
        "\n",
        "    def init_before_training(self):\n",
        "        if self.cwd is None:  # set cwd (current working directory) for saving model\n",
        "            self.cwd = f'./{self.env_name}_{self.agent_class.__name__[5:]}'\n",
        "        os.makedirs(self.cwd, exist_ok=True)\n",
        "\n",
        "\n",
        "def get_gym_env_args(env, if_print: bool) -> dict:\n",
        "    if {'unwrapped', 'observation_space', 'action_space', 'spec'}.issubset(dir(env)):  # isinstance(env, gym.Env):\n",
        "        env_name = env.unwrapped.spec.id\n",
        "        state_shape = env.observation_space.shape\n",
        "        state_dim = state_shape[0] if len(state_shape) == 1 else state_shape  # sometimes state_dim is a list\n",
        "\n",
        "        if_discrete = isinstance(env.action_space, gym.spaces.Discrete)\n",
        "        if if_discrete:  # make sure it is discrete action space\n",
        "            action_dim = env.action_space.n\n",
        "        elif isinstance(env.action_space, gym.spaces.Box):  # make sure it is continuous action space\n",
        "            action_dim = env.action_space.shape[0]\n",
        "\n",
        "    env_args = {'env_name': env_name, 'state_dim': state_dim, 'action_dim': action_dim, 'if_discrete': if_discrete}\n",
        "    print(f\"env_args = {repr(env_args)}\") if if_print else None\n",
        "    return env_args\n",
        "\n",
        "\n",
        "def kwargs_filter(function, kwargs: dict) -> dict:\n",
        "    import inspect\n",
        "    sign = inspect.signature(function).parameters.values()\n",
        "    sign = {val.name for val in sign}\n",
        "    common_args = sign.intersection(kwargs.keys())\n",
        "    return {key: kwargs[key] for key in common_args}  # filtered kwargs\n",
        "\n",
        "\n",
        "def build_env(env_class=None, env_args=None):\n",
        "    if env_class.__module__ == 'gym.envs.registration':  # special rule\n",
        "        env = env_class(id=env_args['env_name'])\n",
        "    else:\n",
        "        env = env_class(**kwargs_filter(env_class.__init__, env_args.copy()))\n",
        "    for attr_str in ('env_name', 'state_dim', 'action_dim', 'if_discrete'):\n",
        "        setattr(env, attr_str, env_args[attr_str])\n",
        "    return env\n",
        "\n",
        "\n",
        "class AgentBase:\n",
        "    def __init__(self, net_dims: [int], state_dim: int, action_dim: int, gpu_id: int = 0, args: Config = Config()):\n",
        "        self.state_dim = state_dim\n",
        "        self.action_dim = action_dim\n",
        "\n",
        "        self.gamma = args.gamma\n",
        "        self.batch_size = args.batch_size\n",
        "        self.repeat_times = args.repeat_times\n",
        "        self.reward_scale = args.reward_scale\n",
        "        self.soft_update_tau = args.soft_update_tau\n",
        "\n",
        "        self.states = None  # assert self.states == (1, state_dim)\n",
        "        self.device = torch.device(f\"cuda:{gpu_id}\" if (torch.cuda.is_available() and (gpu_id >= 0)) else \"cpu\")\n",
        "\n",
        "        act_class = getattr(self, \"act_class\", None)\n",
        "        cri_class = getattr(self, \"cri_class\", None)\n",
        "        self.act = self.act_target = act_class(net_dims, state_dim, action_dim).to(self.device)\n",
        "        self.cri = self.cri_target = cri_class(net_dims, state_dim, action_dim).to(self.device) \\\n",
        "            if cri_class else self.act\n",
        "\n",
        "        self.act_optimizer = torch.optim.Adam(self.act.parameters(), args.learning_rate)\n",
        "        self.cri_optimizer = torch.optim.Adam(self.cri.parameters(), args.learning_rate) \\\n",
        "            if cri_class else self.act_optimizer\n",
        "\n",
        "        self.criterion = torch.nn.SmoothL1Loss()\n",
        "\n",
        "    @staticmethod\n",
        "    def optimizer_update(optimizer, objective: Tensor):\n",
        "        optimizer.zero_grad()\n",
        "        objective.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    @staticmethod\n",
        "    def soft_update(target_net: torch.nn.Module, current_net: torch.nn.Module, tau: float):\n",
        "        for tar, cur in zip(target_net.parameters(), current_net.parameters()):\n",
        "            tar.data.copy_(cur.data * tau + tar.data * (1.0 - tau))\n",
        "\n",
        "\n",
        "class AgentPPO(AgentBase):\n",
        "    def __init__(self, net_dims: [int], state_dim: int, action_dim: int, gpu_id: int = 0, args: Config = Config()):\n",
        "        self.if_off_policy = False\n",
        "        self.act_class = getattr(self, \"act_class\", ActorPPO)\n",
        "        self.cri_class = getattr(self, \"cri_class\", CriticPPO)\n",
        "        AgentBase.__init__(self, net_dims, state_dim, action_dim, gpu_id, args)\n",
        "\n",
        "        self.ratio_clip = getattr(args, \"ratio_clip\", 0.25)  # `ratio.clamp(1 - clip, 1 + clip)`\n",
        "        self.lambda_gae_adv = getattr(args, \"lambda_gae_adv\", 0.95)  # could be 0.80~0.99\n",
        "        self.lambda_entropy = getattr(args, \"lambda_entropy\", 0.01)  # could be 0.00~0.10\n",
        "        self.lambda_entropy = torch.tensor(self.lambda_entropy, dtype=torch.float32, device=self.device)\n",
        "\n",
        "    def explore_env(self, env, horizon_len: int) -> [Tensor]:\n",
        "        states = torch.zeros((horizon_len, self.state_dim), dtype=torch.float32).to(self.device)\n",
        "        actions = torch.zeros((horizon_len, self.action_dim), dtype=torch.float32).to(self.device)\n",
        "        logprobs = torch.zeros(horizon_len, dtype=torch.float32).to(self.device)\n",
        "        rewards = torch.zeros(horizon_len, dtype=torch.float32).to(self.device)\n",
        "        dones = torch.zeros(horizon_len, dtype=torch.bool).to(self.device)\n",
        "\n",
        "        ary_state = self.states[0]\n",
        "\n",
        "        get_action = self.act.get_action\n",
        "        convert = self.act.convert_action_for_env\n",
        "        for i in range(horizon_len):\n",
        "            state = torch.as_tensor(ary_state, dtype=torch.float32, device=self.device)\n",
        "            action, logprob = [t.squeeze(0) for t in get_action(state.unsqueeze(0))[:2]]\n",
        "\n",
        "            ary_action = convert(action).detach().cpu().numpy()\n",
        "            ary_state, reward, done, _, _ = env.step(ary_action)\n",
        "            if done:\n",
        "                ary_state, _ = env.reset()\n",
        "\n",
        "            states[i] = state\n",
        "            actions[i] = action\n",
        "            logprobs[i] = logprob\n",
        "            rewards[i] = reward\n",
        "            dones[i] = done\n",
        "\n",
        "        self.states[0] = ary_state\n",
        "        rewards = (rewards * self.reward_scale).unsqueeze(1)\n",
        "        undones = (1 - dones.type(torch.float32)).unsqueeze(1)\n",
        "        return states, actions, logprobs, rewards, undones\n",
        "\n",
        "    def update_net(self, buffer) -> [float]:\n",
        "        with torch.no_grad():\n",
        "            states, actions, logprobs, rewards, undones = buffer\n",
        "            buffer_size = states.shape[0]\n",
        "\n",
        "            '''get advantages reward_sums'''\n",
        "            bs = 2 ** 10  # set a smaller 'batch_size' when out of GPU memory.\n",
        "            values = [self.cri(states[i:i + bs]) for i in range(0, buffer_size, bs)]\n",
        "            values = torch.cat(values, dim=0).squeeze(1)  # values.shape == (buffer_size, )\n",
        "\n",
        "            advantages = self.get_advantages(rewards, undones, values)  # advantages.shape == (buffer_size, )\n",
        "            reward_sums = advantages + values  # reward_sums.shape == (buffer_size, )\n",
        "            del rewards, undones, values\n",
        "\n",
        "            advantages = (advantages - advantages.mean()) / (advantages.std(dim=0) + 1e-5)\n",
        "        assert logprobs.shape == advantages.shape == reward_sums.shape == (buffer_size,)\n",
        "\n",
        "        '''update network'''\n",
        "        obj_critics = 0.0\n",
        "        obj_actors = 0.0\n",
        "\n",
        "        update_times = int(buffer_size * self.repeat_times / self.batch_size)\n",
        "        assert update_times >= 1\n",
        "        for _ in range(update_times):\n",
        "            indices = torch.randint(buffer_size, size=(self.batch_size,), requires_grad=False)\n",
        "            state = states[indices]\n",
        "            action = actions[indices]\n",
        "            logprob = logprobs[indices]\n",
        "            advantage = advantages[indices]\n",
        "            reward_sum = reward_sums[indices]\n",
        "\n",
        "            value = self.cri(state).squeeze(1)  # critic network predicts the reward_sum (Q value) of state\n",
        "            obj_critic = self.criterion(value, reward_sum)\n",
        "            self.optimizer_update(self.cri_optimizer, obj_critic)\n",
        "\n",
        "            new_logprob, obj_entropy = self.act.get_logprob_entropy(state, action)\n",
        "            ratio = (new_logprob - logprob.detach()).exp()\n",
        "            surrogate1 = advantage * ratio\n",
        "            surrogate2 = advantage * ratio.clamp(1 - self.ratio_clip, 1 + self.ratio_clip)\n",
        "            obj_surrogate = torch.min(surrogate1, surrogate2).mean()\n",
        "\n",
        "            obj_actor = obj_surrogate + obj_entropy.mean() * self.lambda_entropy\n",
        "            self.optimizer_update(self.act_optimizer, -obj_actor)\n",
        "\n",
        "            obj_critics += obj_critic.item()\n",
        "            obj_actors += obj_actor.item()\n",
        "        a_std_log = getattr(self.act, 'a_std_log', torch.zeros(1)).mean()\n",
        "        return obj_critics / update_times, obj_actors / update_times, a_std_log.item()\n",
        "\n",
        "    def get_advantages(self, rewards: Tensor, undones: Tensor, values: Tensor) -> Tensor:\n",
        "        advantages = torch.empty_like(values)  # advantage value\n",
        "\n",
        "        masks = undones * self.gamma\n",
        "        horizon_len = rewards.shape[0]\n",
        "\n",
        "        next_state = torch.tensor(self.states, dtype=torch.float32).to(self.device)\n",
        "        next_value = self.cri(next_state).detach()[0, 0]\n",
        "\n",
        "        advantage = 0  # last_gae_lambda\n",
        "        for t in range(horizon_len - 1, -1, -1):\n",
        "            delta = rewards[t] + masks[t] * next_value - values[t]\n",
        "            advantages[t] = advantage = delta + masks[t] * self.lambda_gae_adv * advantage\n",
        "            next_value = values[t]\n",
        "        return advantages\n",
        "\n",
        "\n",
        "class PendulumEnv(gym.Wrapper):  # a demo of custom gym env\n",
        "    def __init__(self):\n",
        "        gym.logger.set_level(40)  # Block warning\n",
        "        gym_env_name = \"Pendulum-v0\" if gym.__version__ < '0.18.0' else \"Pendulum-v1\"\n",
        "        super().__init__(env=gym.make(gym_env_name))\n",
        "\n",
        "        '''the necessary env information when you design a custom env'''\n",
        "        self.env_name = gym_env_name  # the name of this env.\n",
        "        self.state_dim = self.observation_space.shape[0]  # feature number of state\n",
        "        self.action_dim = self.action_space.shape[0]  # feature number of action\n",
        "        self.if_discrete = False  # discrete action or continuous action\n",
        "\n",
        "    def reset(self) -> np.ndarray:  # reset the agent in env\n",
        "        resetted_env, _ = self.env.reset()\n",
        "        return resetted_env\n",
        "\n",
        "    def step(self, action: np.ndarray) -> (np.ndarray, float, bool, dict):  # agent interacts in env\n",
        "        # We suggest that adjust action space to (-1, +1) when designing a custom env.\n",
        "        state, reward, done, info_dict, _ = self.env.step(action * 2)\n",
        "        return state.reshape(self.state_dim), float(reward), done, info_dict\n",
        "\n",
        "\n",
        "def train_agent(args: Config):\n",
        "    args.init_before_training()\n",
        "\n",
        "    env = build_env(args.env_class, args.env_args)\n",
        "    agent = args.agent_class(args.net_dims, args.state_dim, args.action_dim, gpu_id=args.gpu_id, args=args)\n",
        "\n",
        "    new_env, _ = env.reset()\n",
        "    agent.states = new_env[np.newaxis, :]\n",
        "\n",
        "    evaluator = Evaluator(eval_env=build_env(args.env_class, args.env_args),\n",
        "                          eval_per_step=args.eval_per_step,\n",
        "                          eval_times=args.eval_times,\n",
        "                          cwd=args.cwd)\n",
        "    torch.set_grad_enabled(False)\n",
        "    while True: # start training\n",
        "        buffer_items = agent.explore_env(env, args.horizon_len)\n",
        "\n",
        "        torch.set_grad_enabled(True)\n",
        "        logging_tuple = agent.update_net(buffer_items)\n",
        "        torch.set_grad_enabled(False)\n",
        "\n",
        "        evaluator.evaluate_and_save(agent.act, args.horizon_len, logging_tuple)\n",
        "        if (evaluator.total_step > args.break_step) or os.path.exists(f\"{args.cwd}/stop\"):\n",
        "            torch.save(agent.act.state_dict(), args.cwd + '/actor.pth')\n",
        "            break  # stop training when reach `break_step` or `mkdir cwd/stop`\n",
        "\n",
        "\n",
        "def render_agent(env_class, env_args: dict, net_dims: [int], agent_class, actor_path: str, render_times: int = 8):\n",
        "    env = build_env(env_class, env_args)\n",
        "\n",
        "    state_dim = env_args['state_dim']\n",
        "    action_dim = env_args['action_dim']\n",
        "    agent = agent_class(net_dims, state_dim, action_dim, gpu_id=-1)\n",
        "    actor = agent.act\n",
        "\n",
        "    print(f\"| render and load actor from: {actor_path}\")\n",
        "    actor.load_state_dict(torch.load(actor_path, map_location=lambda storage, loc: storage))\n",
        "    for i in range(render_times):\n",
        "        cumulative_reward, episode_step = get_rewards_and_steps(env, actor, if_render=True)\n",
        "        print(f\"|{i:4}  cumulative_reward {cumulative_reward:9.3f}  episode_step {episode_step:5.0f}\")\n",
        "\n",
        "\n",
        "class Evaluator:\n",
        "    def __init__(self, eval_env, eval_per_step: int = 1e4, eval_times: int = 8, cwd: str = '.'):\n",
        "        self.cwd = cwd\n",
        "        self.env_eval = eval_env\n",
        "        self.eval_step = 0\n",
        "        self.total_step = 0\n",
        "        self.start_time = time.time()\n",
        "        self.eval_times = eval_times  # number of times that get episodic cumulative return\n",
        "        self.eval_per_step = eval_per_step  # evaluate the agent per training steps\n",
        "\n",
        "        self.recorder = []\n",
        "        print(f\"\\n| `step`: Number of samples, or total training steps, or running times of `env.step()`.\"\n",
        "              f\"\\n| `time`: Time spent from the start of training to this moment.\"\n",
        "              f\"\\n| `avgR`: Average value of cumulative rewards, which is the sum of rewards in an episode.\"\n",
        "              f\"\\n| `stdR`: Standard dev of cumulative rewards, which is the sum of rewards in an episode.\"\n",
        "              f\"\\n| `avgS`: Average of steps in an episode.\"\n",
        "              f\"\\n| `objC`: Objective of Critic network. Or call it loss function of critic network.\"\n",
        "              f\"\\n| `objA`: Objective of Actor network. It is the average Q value of the critic network.\"\n",
        "              f\"\\n| {'step':>8}  {'time':>8}  | {'avgR':>8}  {'stdR':>6}  {'avgS':>6}  | {'objC':>8}  {'objA':>8}\")\n",
        "\n",
        "    def evaluate_and_save(self, actor, horizon_len: int, logging_tuple: tuple):\n",
        "        self.total_step += horizon_len\n",
        "        if self.eval_step + self.eval_per_step > self.total_step:\n",
        "            return\n",
        "        self.eval_step = self.total_step\n",
        "\n",
        "        rewards_steps_ary = [get_rewards_and_steps(self.env_eval, actor) for _ in range(self.eval_times)]\n",
        "        rewards_steps_ary = np.array(rewards_steps_ary, dtype=np.float32)\n",
        "        avg_r = rewards_steps_ary[:, 0].mean()  # average of cumulative rewards\n",
        "        std_r = rewards_steps_ary[:, 0].std()  # std of cumulative rewards\n",
        "        avg_s = rewards_steps_ary[:, 1].mean()  # average of steps in an episode\n",
        "\n",
        "        used_time = time.time() - self.start_time\n",
        "        self.recorder.append((self.total_step, used_time, avg_r))\n",
        "\n",
        "        print(f\"| {self.total_step:8.2e}  {used_time:8.0f}  \"\n",
        "              f\"| {avg_r:8.2f}  {std_r:6.2f}  {avg_s:6.0f}  \"\n",
        "              f\"| {logging_tuple[0]:8.2f}  {logging_tuple[1]:8.2f}\")\n",
        "\n",
        "\n",
        "def get_rewards_and_steps(env, actor, if_render: bool = False) -> (float, int):  # cumulative_rewards and episode_steps\n",
        "    device = next(actor.parameters()).device  # net.parameters() is a Python generator.\n",
        "\n",
        "    state, _ = env.reset()\n",
        "    episode_steps = 0\n",
        "    cumulative_returns = 0.0  # sum of rewards in an episode\n",
        "    for episode_steps in range(12345):\n",
        "        tensor_state = torch.as_tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n",
        "        tensor_action = actor(tensor_state)\n",
        "        action = tensor_action.detach().cpu().numpy()[0]  # not need detach(), because using torch.no_grad() outside\n",
        "        state, reward, done, _, _ = env.step(action)\n",
        "        cumulative_returns += reward\n",
        "\n",
        "        if if_render:\n",
        "            env.render()\n",
        "        if done:\n",
        "            break\n",
        "    return cumulative_returns, episode_steps + 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tzAw9k26nAC"
      },
      "source": [
        "## DRL Agent Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pwCbbocm6PHM"
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import torch\n",
        "# from elegantrl.agents import AgentA2C\n",
        "\n",
        "MODELS = {\"ppo\": AgentPPO}\n",
        "OFF_POLICY_MODELS = [\"ddpg\", \"td3\", \"sac\"]\n",
        "ON_POLICY_MODELS = [\"ppo\"]\n",
        "# MODEL_KWARGS = {x: config.__dict__[f\"{x.upper()}_PARAMS\"] for x in MODELS.keys()}\n",
        "#\n",
        "# NOISE = {\n",
        "#     \"normal\": NormalActionNoise,\n",
        "#     \"ornstein_uhlenbeck\": OrnsteinUhlenbeckActionNoise,\n",
        "# }\n",
        "\n",
        "\n",
        "class DRLAgent:\n",
        "    \"\"\"Implementations of DRL algorithms\n",
        "    Attributes\n",
        "    ----------\n",
        "        env: gym environment class\n",
        "            user-defined class\n",
        "    Methods\n",
        "    -------\n",
        "        get_model()\n",
        "            setup DRL algorithms\n",
        "        train_model()\n",
        "            train DRL algorithms in a train dataset\n",
        "            and output the trained model\n",
        "        DRL_prediction()\n",
        "            make a prediction in a test dataset and get results\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, env, price_array, tech_array, turbulence_array):\n",
        "        self.env = env\n",
        "        self.price_array = price_array\n",
        "        self.tech_array = tech_array\n",
        "        self.turbulence_array = turbulence_array\n",
        "\n",
        "    def get_model(self, model_name, model_kwargs):\n",
        "        env_config = {\n",
        "            \"price_array\": self.price_array,\n",
        "            \"tech_array\": self.tech_array,\n",
        "            \"turbulence_array\": self.turbulence_array,\n",
        "            \"if_train\": True,\n",
        "        }\n",
        "        environment = self.env(config=env_config)\n",
        "        env_args = {'config': env_config,\n",
        "              'env_name': environment.env_name,\n",
        "              'state_dim': environment.state_dim,\n",
        "              'action_dim': environment.action_dim,\n",
        "              'if_discrete': False}\n",
        "        agent = MODELS[model_name]\n",
        "        if model_name not in MODELS:\n",
        "            raise NotImplementedError(\"NotImplementedError\")\n",
        "        model = Config(agent_class=agent, env_class=self.env, env_args=env_args)\n",
        "        model.if_off_policy = model_name in OFF_POLICY_MODELS\n",
        "        if model_kwargs is not None:\n",
        "            try:\n",
        "                model.learning_rate = model_kwargs[\"learning_rate\"]\n",
        "                model.batch_size = model_kwargs[\"batch_size\"]\n",
        "                model.gamma = model_kwargs[\"gamma\"]\n",
        "                model.seed = model_kwargs[\"seed\"]\n",
        "                model.net_dims = model_kwargs[\"net_dimension\"]\n",
        "                model.target_step = model_kwargs[\"target_step\"]\n",
        "                model.eval_gap = model_kwargs[\"eval_gap\"]\n",
        "                model.eval_times = model_kwargs[\"eval_times\"]\n",
        "            except BaseException:\n",
        "                raise ValueError(\n",
        "                    \"Fail to read arguments, please check 'model_kwargs' input.\"\n",
        "                )\n",
        "        return model\n",
        "\n",
        "    def train_model(self, model, cwd, total_timesteps=5000):\n",
        "        model.cwd = cwd\n",
        "        model.break_step = total_timesteps\n",
        "        train_agent(model)\n",
        "\n",
        "    @staticmethod\n",
        "    def DRL_prediction(model_name, cwd, net_dimension, environment):\n",
        "        if model_name not in MODELS:\n",
        "            raise NotImplementedError(\"NotImplementedError\")\n",
        "        agent_class = MODELS[model_name]\n",
        "        environment.env_num = 1\n",
        "        agent = agent_class(net_dimension, environment.state_dim, environment.action_dim)\n",
        "        actor = agent.act\n",
        "        # load agent\n",
        "        try:\n",
        "            cwd = cwd + '/actor.pth'\n",
        "            print(f\"| load actor from: {cwd}\")\n",
        "            actor.load_state_dict(torch.load(cwd, map_location=lambda storage, loc: storage))\n",
        "            act = actor\n",
        "            device = agent.device\n",
        "        except BaseException:\n",
        "            raise ValueError(\"Fail to load agent!\")\n",
        "\n",
        "        # test on the testing env\n",
        "        _torch = torch\n",
        "        state, _ = environment.reset()\n",
        "        episode_returns = []  # the cumulative_return / initial_account\n",
        "        episode_total_assets = [environment.initial_total_asset]\n",
        "        with _torch.no_grad():\n",
        "            for i in range(environment.max_step):\n",
        "                s_tensor = _torch.as_tensor((state,), device=device)\n",
        "                a_tensor = act(s_tensor)  # action_tanh = act.forward()\n",
        "                action = (\n",
        "                    a_tensor.detach().cpu().numpy()[0]\n",
        "                )  # not need detach(), because with torch.no_grad() outside\n",
        "                state, reward, done, _, _ = environment.step(action)\n",
        "\n",
        "                total_asset = (\n",
        "                    environment.amount\n",
        "                    + (\n",
        "                        environment.price_ary[environment.day] * environment.stocks\n",
        "                    ).sum()\n",
        "                )\n",
        "                episode_total_assets.append(total_asset)\n",
        "                episode_return = total_asset / environment.initial_total_asset\n",
        "                episode_returns.append(episode_return)\n",
        "                if done:\n",
        "                    break\n",
        "        print(\"Test Finished!\")\n",
        "        # return episode total_assets on testing data\n",
        "        print(\"episode_return\", episode_return)\n",
        "        return episode_total_assets\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjLda8No6pvI"
      },
      "source": [
        "## Train & Test Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j8-e03ev32oz"
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "from finrl.config import ERL_PARAMS\n",
        "from finrl.config import INDICATORS\n",
        "from finrl.config import RLlib_PARAMS\n",
        "from finrl.config import SAC_PARAMS\n",
        "from finrl.config import TRAIN_END_DATE\n",
        "from finrl.config import TRAIN_START_DATE\n",
        "from finrl.config_tickers import DOW_30_TICKER\n",
        "from finrl.meta.data_processor import DataProcessor\n",
        "\n",
        "# construct environment\n",
        "\n",
        "\n",
        "def train(\n",
        "    start_date,\n",
        "    end_date,\n",
        "    ticker_list,\n",
        "    data_source,\n",
        "    time_interval,\n",
        "    technical_indicator_list,\n",
        "    drl_lib,\n",
        "    env,\n",
        "    model_name,\n",
        "    if_vix=True,\n",
        "    **kwargs,\n",
        "):\n",
        "    # download data\n",
        "    dp = DataProcessor(data_source, **kwargs)\n",
        "    data = dp.download_data(ticker_list, start_date, end_date, time_interval)\n",
        "    data = dp.clean_data(data)\n",
        "    data = dp.add_technical_indicator(data, technical_indicator_list)\n",
        "    if if_vix:\n",
        "        data = dp.add_vix(data)\n",
        "    else:\n",
        "        data = dp.add_turbulence(data)\n",
        "    price_array, tech_array, turbulence_array = dp.df_to_array(data, if_vix)\n",
        "    env_config = {\n",
        "        \"price_array\": price_array,\n",
        "        \"tech_array\": tech_array,\n",
        "        \"turbulence_array\": turbulence_array,\n",
        "        \"if_train\": True,\n",
        "    }\n",
        "    env_instance = env(config=env_config)\n",
        "\n",
        "    # read parameters\n",
        "    cwd = kwargs.get(\"cwd\", \"./\" + str(model_name))\n",
        "\n",
        "    if drl_lib == \"elegantrl\":\n",
        "        DRLAgent_erl = DRLAgent\n",
        "        break_step = kwargs.get(\"break_step\", 1e6)\n",
        "        erl_params = kwargs.get(\"erl_params\")\n",
        "        agent = DRLAgent_erl(\n",
        "            env=env,\n",
        "            price_array=price_array,\n",
        "            tech_array=tech_array,\n",
        "            turbulence_array=turbulence_array,\n",
        "        )\n",
        "        model = agent.get_model(model_name, model_kwargs=erl_params)\n",
        "        trained_model = agent.train_model(\n",
        "            model=model, cwd=cwd, total_timesteps=break_step\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Evsg8QtEDHDO"
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "from finrl.config import INDICATORS\n",
        "from finrl.config import RLlib_PARAMS\n",
        "from finrl.config import TEST_END_DATE\n",
        "from finrl.config import TEST_START_DATE\n",
        "from finrl.config_tickers import DOW_30_TICKER\n",
        "\n",
        "def test(\n",
        "    start_date,\n",
        "    end_date,\n",
        "    ticker_list,\n",
        "    data_source,\n",
        "    time_interval,\n",
        "    technical_indicator_list,\n",
        "    drl_lib,\n",
        "    env,\n",
        "    model_name,\n",
        "    if_vix=True,\n",
        "    **kwargs,\n",
        "):\n",
        "\n",
        "    # import data processor\n",
        "    from finrl.meta.data_processor import DataProcessor\n",
        "\n",
        "    # fetch data\n",
        "    dp = DataProcessor(data_source, **kwargs)\n",
        "    data = dp.download_data(ticker_list, start_date, end_date, time_interval)\n",
        "    data = dp.clean_data(data)\n",
        "    data = dp.add_technical_indicator(data, technical_indicator_list)\n",
        "\n",
        "    if if_vix:\n",
        "        data = dp.add_vix(data)\n",
        "    else:\n",
        "        data = dp.add_turbulence(data)\n",
        "    price_array, tech_array, turbulence_array = dp.df_to_array(data, if_vix)\n",
        "\n",
        "    env_config = {\n",
        "        \"price_array\": price_array,\n",
        "        \"tech_array\": tech_array,\n",
        "        \"turbulence_array\": turbulence_array,\n",
        "        \"if_train\": False,\n",
        "    }\n",
        "    env_instance = env(config=env_config)\n",
        "\n",
        "    # load elegantrl needs state dim, action dim and net dim\n",
        "    net_dimension = kwargs.get(\"net_dimension\", 2**7)\n",
        "    cwd = kwargs.get(\"cwd\", \"./\" + str(model_name))\n",
        "    print(\"price_array: \", len(price_array))\n",
        "\n",
        "    if drl_lib == \"elegantrl\":\n",
        "        DRLAgent_erl = DRLAgent\n",
        "        episode_total_assets = DRLAgent_erl.DRL_prediction(\n",
        "            model_name=model_name,\n",
        "            cwd=cwd,\n",
        "            net_dimension=net_dimension,\n",
        "            environment=env_instance,\n",
        "        )\n",
        "        return episode_total_assets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pf5aVHAU-xF6"
      },
      "source": [
        "## Import Dow Jones 30 Symbols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jx25TA_X87F-"
      },
      "outputs": [],
      "source": [
        "ticker_list = DOW_30_TICKER\n",
        "action_dim = len(DOW_30_TICKER)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UIV0kO_y-inG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff708a25-9da1-4de6-9025-efa5e2ba2c04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['AXP', 'AMGN', 'AAPL', 'BA', 'CAT', 'CSCO', 'CVX', 'GS', 'HD', 'HON', 'IBM', 'INTC', 'JNJ', 'KO', 'JPM', 'MCD', 'MMM', 'MRK', 'MSFT', 'NKE', 'PG', 'TRV', 'UNH', 'CRM', 'VZ', 'V', 'WBA', 'WMT', 'DIS', 'DOW']\n"
          ]
        }
      ],
      "source": [
        "print(ticker_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CnqQ-cC5-rfO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddfb9e10-00ac-467e-eb8b-1e3038816a24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['macd', 'boll_ub', 'boll_lb', 'rsi_30', 'cci_30', 'dx_30', 'close_30_sma', 'close_60_sma']\n"
          ]
        }
      ],
      "source": [
        "print(INDICATORS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZMkcyjZ-25l"
      },
      "source": [
        "## Calculate the DRL state dimension manually for paper trading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GLfkTsXK-e90"
      },
      "outputs": [],
      "source": [
        "# amount + (turbulence, turbulence_bool) + (price, shares, cd (holding time)) * stock_dim + tech_dim\n",
        "state_dim = 1 + 2 + 3 * action_dim + len(INDICATORS) * action_dim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QqUkvImG-n66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c2b17b3-e9e9-4dca-fa96-478e818c23f5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "333"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "state_dim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vTRPW04PfnoK"
      },
      "outputs": [],
      "source": [
        "env = StockTradingEnv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J25MuZLiGqCP"
      },
      "source": [
        "## Show the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puJZWm8NHtSN"
      },
      "source": [
        "### Step 1. Pick a data source"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ZCru8f7GqgL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76f3106c-2443-4376-ae2d-25f3a4f32c73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alpaca successfully connected\n"
          ]
        }
      ],
      "source": [
        "DP = DataProcessor(data_source = 'alpaca',\n",
        "                  API_KEY = API_KEY,\n",
        "                  API_SECRET = API_SECRET,\n",
        "                  API_BASE_URL = API_BASE_URL\n",
        "                  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvPEW2mYHvkR"
      },
      "source": [
        "### Step 2. Get ticker list, Set start date and end date, specify the data frequency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NPNxj6c8HIiE"
      },
      "outputs": [],
      "source": [
        "data = DP.download_data(start_date = '2021-10-04',\n",
        "                       end_date = '2021-10-08',\n",
        "                       ticker_list = ticker_list,\n",
        "                       time_interval= '1Min')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pPcazCq1d5ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15086a6a-c3b1-4eee-bece-1796501cc1f7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1950"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "data['timestamp'].nunique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i46jGdE0IAel"
      },
      "source": [
        "### Step 3. Data Cleaning & Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x9euUsEPHWFK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13b36042-bac1-483e-faf6-7d0cecdb89ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data cleaning started\n",
            "align start and end dates\n",
            "produce full timestamp index\n",
            "Start processing tickers\n",
            "ticker list complete\n",
            "Start concat and rename\n",
            "Data clean finished!\n",
            "Started adding Indicators\n",
            "Running Loop\n",
            "Restore Timestamps\n",
            "Finished adding Indicators\n",
            "Data cleaning started\n",
            "align start and end dates\n",
            "produce full timestamp index\n",
            "Start processing tickers\n",
            "ticker list complete\n",
            "Start concat and rename\n",
            "Data clean finished!\n"
          ]
        }
      ],
      "source": [
        "data = DP.clean_data(data)\n",
        "data = DP.add_technical_indicator(data, INDICATORS)\n",
        "data = DP.add_vix(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GOcPTaAgHdxa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afba5291-57c6-435a-8ed1-4675fbaf8378"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(58500, 16)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbu03L_UIMWt"
      },
      "source": [
        "### Step 4. Transform to numpy array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rzj0vjZZHdGM"
      },
      "outputs": [],
      "source": [
        "price_array, tech_array, turbulence_array = DP.df_to_array(data, if_vix=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eW0UDAXI1nEa"
      },
      "source": [
        "# Part 2: Train the agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lArLOFcJ7VMO"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g1F84mebj4gu"
      },
      "outputs": [],
      "source": [
        "ERL_PARAMS = {\"learning_rate\": 3e-6,\"batch_size\": 2048,\"gamma\":  0.985,\n",
        "        \"seed\":312,\"net_dimension\":[128,64], \"target_step\":5000, \"eval_gap\":30,\n",
        "        \"eval_times\":1}\n",
        "env = StockTradingEnv\n",
        "#if you want to use larger datasets (change to longer period), and it raises error,\n",
        "#please try to increase \"target_step\". It should be larger than the episode steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BxcNI2fdNjip",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73576d81-71d7-4872-e825-5012863bb223"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alpaca successfully connected\n",
            "Data cleaning started\n",
            "align start and end dates\n",
            "produce full timestamp index\n",
            "Start processing tickers\n",
            "ticker list complete\n",
            "Start concat and rename\n",
            "Data clean finished!\n",
            "Started adding Indicators\n",
            "Running Loop\n",
            "Restore Timestamps\n",
            "Finished adding Indicators\n",
            "Data cleaning started\n",
            "align start and end dates\n",
            "produce full timestamp index\n",
            "Start processing tickers\n",
            "ticker list complete\n",
            "Start concat and rename\n",
            "Data clean finished!\n",
            "\n",
            "| `step`: Number of samples, or total training steps, or running times of `env.step()`.\n",
            "| `time`: Time spent from the start of training to this moment.\n",
            "| `avgR`: Average value of cumulative rewards, which is the sum of rewards in an episode.\n",
            "| `stdR`: Standard dev of cumulative rewards, which is the sum of rewards in an episode.\n",
            "| `avgS`: Average of steps in an episode.\n",
            "| `objC`: Objective of Critic network. Or call it loss function of critic network.\n",
            "| `objA`: Objective of Actor network. It is the average Q value of the critic network.\n",
            "|     step      time  |     avgR    stdR    avgS  |     objC      objA\n",
            "| 2.00e+04        27  |   -23.68    0.00    1949  |     0.68      0.41\n",
            "| 4.00e+04        54  |   -24.35    0.00    1949  |     0.46      0.43\n",
            "| 6.00e+04        80  |   -27.29    0.00    1949  |     0.35      0.43\n",
            "| 8.00e+04       108  |   -25.98    0.00    1949  |     0.32      0.44\n",
            "| 1.00e+05       136  |   -26.51    0.00    1949  |     0.41      0.41\n"
          ]
        }
      ],
      "source": [
        "train(start_date = '2022-08-25',\n",
        "      end_date = '2022-08-31',\n",
        "      ticker_list = ticker_list,\n",
        "      data_source = 'alpaca',\n",
        "      time_interval= '1Min',\n",
        "      technical_indicator_list= INDICATORS,\n",
        "      drl_lib='elegantrl',\n",
        "      env=env,\n",
        "      model_name='ppo',\n",
        "      if_vix=True,\n",
        "      API_KEY = API_KEY,\n",
        "      API_SECRET = API_SECRET,\n",
        "      API_BASE_URL = API_BASE_URL,\n",
        "      erl_params=ERL_PARAMS,\n",
        "      cwd='./papertrading_erl', #current_working_dir\n",
        "      break_step=1e5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g37WugV_1pAS"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SxYoWCDa02TW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae7d494e-b6f3-4c0c-e7ea-71fd4b773669"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alpaca successfully connected\n",
            "Data cleaning started\n",
            "align start and end dates\n",
            "produce full timestamp index\n",
            "Start processing tickers\n",
            "ticker list complete\n",
            "Start concat and rename\n",
            "Data clean finished!\n",
            "Started adding Indicators\n",
            "Running Loop\n",
            "Restore Timestamps\n",
            "Finished adding Indicators\n",
            "Data cleaning started\n",
            "align start and end dates\n",
            "produce full timestamp index\n",
            "Start processing tickers\n",
            "ticker list complete\n",
            "Start concat and rename\n",
            "Data clean finished!\n",
            "price_array:  780\n",
            "| load actor from: ./papertrading_erl/actor.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-50b532088087>:104: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
            "  s_tensor = _torch.as_tensor((state,), device=device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Finished!\n",
            "episode_return 0.999503609788422\n"
          ]
        }
      ],
      "source": [
        "account_value_erl=test(start_date = '2022-09-01',\n",
        "                      end_date = '2022-09-02',\n",
        "                      ticker_list = ticker_list,\n",
        "                      data_source = 'alpaca',\n",
        "                      time_interval= '1Min',\n",
        "                      technical_indicator_list= INDICATORS,\n",
        "                      drl_lib='elegantrl',\n",
        "                      env=env,\n",
        "                      model_name='ppo',\n",
        "                      if_vix=True,\n",
        "                      API_KEY = API_KEY,\n",
        "                      API_SECRET = API_SECRET,\n",
        "                      API_BASE_URL = API_BASE_URL,\n",
        "                      cwd='./papertrading_erl',\n",
        "                      net_dimension = ERL_PARAMS['net_dimension'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8aNQ58X7avM"
      },
      "source": [
        "## Use full data to train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CQ9_Yv41r88"
      },
      "source": [
        "After tuning well, retrain on the training and testing sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cUSgbwt_10V3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e3ba164-66eb-46e0-d8a2-a1ac8a1a8498"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alpaca successfully connected\n",
            "Data cleaning started\n",
            "align start and end dates\n",
            "produce full timestamp index\n",
            "Start processing tickers\n",
            "ticker list complete\n",
            "Start concat and rename\n",
            "Data clean finished!\n",
            "Started adding Indicators\n",
            "Running Loop\n",
            "Restore Timestamps\n",
            "Finished adding Indicators\n",
            "Data cleaning started\n",
            "align start and end dates\n",
            "produce full timestamp index\n",
            "Start processing tickers\n",
            "ticker list complete\n",
            "Start concat and rename\n",
            "Data clean finished!\n",
            "\n",
            "| `step`: Number of samples, or total training steps, or running times of `env.step()`.\n",
            "| `time`: Time spent from the start of training to this moment.\n",
            "| `avgR`: Average value of cumulative rewards, which is the sum of rewards in an episode.\n",
            "| `stdR`: Standard dev of cumulative rewards, which is the sum of rewards in an episode.\n",
            "| `avgS`: Average of steps in an episode.\n",
            "| `objC`: Objective of Critic network. Or call it loss function of critic network.\n",
            "| `objA`: Objective of Actor network. It is the average Q value of the critic network.\n",
            "|     step      time  |     avgR    stdR    avgS  |     objC      objA\n",
            "| 2.00e+04        26  |   -26.02    0.00    2729  |     0.46      0.41\n",
            "| 4.00e+04        51  |   -25.31    0.00    2729  |     0.40      0.44\n",
            "| 6.00e+04        77  |   -26.84    0.00    2729  |     0.43      0.41\n",
            "| 8.00e+04       103  |   -26.18    0.00    2729  |     0.47      0.42\n",
            "| 1.00e+05       130  |   -24.84    0.00    2729  |     0.40      0.43\n",
            "| 1.20e+05       155  |   -25.34    0.00    2729  |     0.41      0.42\n",
            "| 1.40e+05       179  |   -24.72    0.00    2729  |     0.47      0.44\n",
            "| 1.60e+05       205  |   -25.49    0.00    2729  |     0.38      0.43\n",
            "| 1.80e+05       230  |   -26.28    0.00    2729  |     0.40      0.42\n",
            "| 2.00e+05       255  |   -24.96    0.00    2729  |     0.43      0.42\n"
          ]
        }
      ],
      "source": [
        "train(start_date = '2022-08-25',\n",
        "      end_date = '2022-09-02',\n",
        "      ticker_list = ticker_list,\n",
        "      data_source = 'alpaca',\n",
        "      time_interval= '1Min',\n",
        "      technical_indicator_list= INDICATORS,\n",
        "      drl_lib='elegantrl',\n",
        "      env=env,\n",
        "      model_name='ppo',\n",
        "      if_vix=True,\n",
        "      API_KEY = API_KEY,\n",
        "      API_SECRET = API_SECRET,\n",
        "      API_BASE_URL = API_BASE_URL,\n",
        "      erl_params=ERL_PARAMS,\n",
        "      cwd='./papertrading_erl_retrain',\n",
        "      break_step=2e5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIQN6Ggt7gXY"
      },
      "source": [
        "# Part 3: Deploy the agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFoxkigg1zXa"
      },
      "source": [
        "## Setup Alpaca Paper trading environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LpkoZpYzfneS"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "import threading\n",
        "from finrl.meta.data_processors.processor_alpaca import AlpacaProcessor\n",
        "import alpaca_trade_api as tradeapi\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import gym\n",
        "\n",
        "class AlpacaPaperTrading():\n",
        "\n",
        "    def __init__(self,ticker_list, time_interval, drl_lib, agent, cwd, net_dim,\n",
        "                 state_dim, action_dim, API_KEY, API_SECRET,\n",
        "                 API_BASE_URL, tech_indicator_list, turbulence_thresh=30,\n",
        "                 max_stock=1e2, latency = None):\n",
        "        #load agent\n",
        "        self.drl_lib = drl_lib\n",
        "        if agent =='ppo':\n",
        "            if drl_lib == 'elegantrl':\n",
        "                agent_class = AgentPPO\n",
        "                agent = agent_class(net_dim, state_dim, action_dim)\n",
        "                actor = agent.act\n",
        "                # load agent\n",
        "                try:\n",
        "                    cwd = cwd + '/actor.pth'\n",
        "                    print(f\"| load actor from: {cwd}\")\n",
        "                    actor.load_state_dict(torch.load(cwd, map_location=lambda storage, loc: storage))\n",
        "                    self.act = actor\n",
        "                    self.device = agent.device\n",
        "                except BaseException:\n",
        "                    raise ValueError(\"Fail to load agent!\")\n",
        "\n",
        "            elif drl_lib == 'rllib':\n",
        "                from ray.rllib.agents import ppo\n",
        "                from ray.rllib.agents.ppo.ppo import PPOTrainer\n",
        "\n",
        "                config = ppo.DEFAULT_CONFIG.copy()\n",
        "                config['env'] = StockEnvEmpty\n",
        "                config[\"log_level\"] = \"WARN\"\n",
        "                config['env_config'] = {'state_dim':state_dim,\n",
        "                            'action_dim':action_dim,}\n",
        "                trainer = PPOTrainer(env=StockEnvEmpty, config=config)\n",
        "                trainer.restore(cwd)\n",
        "                try:\n",
        "                    trainer.restore(cwd)\n",
        "                    self.agent = trainer\n",
        "                    print(\"Restoring from checkpoint path\", cwd)\n",
        "                except:\n",
        "                    raise ValueError('Fail to load agent!')\n",
        "\n",
        "            elif drl_lib == 'stable_baselines3':\n",
        "                from stable_baselines3 import PPO\n",
        "\n",
        "                try:\n",
        "                    #load agent\n",
        "                    self.model = PPO.load(cwd)\n",
        "                    print(\"Successfully load model\", cwd)\n",
        "                except:\n",
        "                    raise ValueError('Fail to load agent!')\n",
        "\n",
        "            else:\n",
        "                raise ValueError('The DRL library input is NOT supported yet. Please check your input.')\n",
        "\n",
        "        else:\n",
        "            raise ValueError('Agent input is NOT supported yet.')\n",
        "\n",
        "\n",
        "\n",
        "        #connect to Alpaca trading API\n",
        "        try:\n",
        "            self.alpaca = tradeapi.REST(API_KEY,API_SECRET,API_BASE_URL, 'v2')\n",
        "        except:\n",
        "            raise ValueError('Fail to connect Alpaca. Please check account info and internet connection.')\n",
        "\n",
        "        #read trading time interval\n",
        "        if time_interval == '1s':\n",
        "            self.time_interval = 1\n",
        "        elif time_interval == '5s':\n",
        "            self.time_interval = 5\n",
        "        elif time_interval == '1Min':\n",
        "            self.time_interval = 60\n",
        "        elif time_interval == '5Min':\n",
        "            self.time_interval = 60 * 5\n",
        "        elif time_interval == '15Min':\n",
        "            self.time_interval = 60 * 15\n",
        "        else:\n",
        "            raise ValueError('Time interval input is NOT supported yet.')\n",
        "\n",
        "        #read trading settings\n",
        "        self.tech_indicator_list = tech_indicator_list\n",
        "        self.turbulence_thresh = turbulence_thresh\n",
        "        self.max_stock = max_stock\n",
        "\n",
        "        #initialize account\n",
        "        self.stocks = np.asarray([0] * len(ticker_list)) #stocks holding\n",
        "        self.stocks_cd = np.zeros_like(self.stocks)\n",
        "        self.cash = None #cash record\n",
        "        self.stocks_df = pd.DataFrame(self.stocks, columns=['stocks'], index = ticker_list)\n",
        "        self.asset_list = []\n",
        "        self.price = np.asarray([0] * len(ticker_list))\n",
        "        self.stockUniverse = ticker_list\n",
        "        self.turbulence_bool = 0\n",
        "        self.equities = []\n",
        "\n",
        "    def test_latency(self, test_times = 10):\n",
        "        total_time = 0\n",
        "        for i in range(0, test_times):\n",
        "            time0 = time.time()\n",
        "            self.get_state()\n",
        "            time1 = time.time()\n",
        "            temp_time = time1 - time0\n",
        "            total_time += temp_time\n",
        "        latency = total_time/test_times\n",
        "        print('latency for data processing: ', latency)\n",
        "        return latency\n",
        "\n",
        "    def run(self):\n",
        "        orders = self.alpaca.list_orders(status=\"open\")\n",
        "        for order in orders:\n",
        "          self.alpaca.cancel_order(order.id)\n",
        "\n",
        "        # Wait for market to open.\n",
        "        print(\"Waiting for market to open...\")\n",
        "        self.awaitMarketOpen()\n",
        "        print(\"Market opened.\")\n",
        "\n",
        "        while True:\n",
        "\n",
        "          # Figure out when the market will close so we can prepare to sell beforehand.\n",
        "          clock = self.alpaca.get_clock()\n",
        "          closingTime = clock.next_close.replace(tzinfo=datetime.timezone.utc).timestamp()\n",
        "          currTime = clock.timestamp.replace(tzinfo=datetime.timezone.utc).timestamp()\n",
        "          self.timeToClose = closingTime - currTime\n",
        "\n",
        "          if(self.timeToClose < (60)):\n",
        "            # Close all positions when 1 minutes til market close.\n",
        "            print(\"Market closing soon. Stop trading.\")\n",
        "            break\n",
        "\n",
        "            '''# Close all positions when 1 minutes til market close.\n",
        "            print(\"Market closing soon.  Closing positions.\")\n",
        "\n",
        "            threads = []\n",
        "            positions = self.alpaca.list_positions()\n",
        "            for position in positions:\n",
        "              if(position.side == 'long'):\n",
        "                orderSide = 'sell'\n",
        "              else:\n",
        "                orderSide = 'buy'\n",
        "              qty = abs(int(float(position.qty)))\n",
        "              respSO = []\n",
        "              tSubmitOrder = threading.Thread(target=self.submitOrder(qty, position.symbol, orderSide, respSO))\n",
        "              tSubmitOrder.start()\n",
        "              threads.append(tSubmitOrder)    # record thread for joining later\n",
        "\n",
        "            for x in threads:   #  wait for all threads to complete\n",
        "                x.join()\n",
        "            # Run script again after market close for next trading day.\n",
        "            print(\"Sleeping until market close (15 minutes).\")\n",
        "            time.sleep(60 * 15)'''\n",
        "\n",
        "          else:\n",
        "            self.trade()\n",
        "            last_equity = float(self.alpaca.get_account().last_equity)\n",
        "            cur_time = time.time()\n",
        "            self.equities.append([cur_time,last_equity])\n",
        "            time.sleep(self.time_interval)\n",
        "\n",
        "    def awaitMarketOpen(self):\n",
        "        isOpen = self.alpaca.get_clock().is_open\n",
        "        while(not isOpen):\n",
        "          clock = self.alpaca.get_clock()\n",
        "          openingTime = clock.next_open.replace(tzinfo=datetime.timezone.utc).timestamp()\n",
        "          currTime = clock.timestamp.replace(tzinfo=datetime.timezone.utc).timestamp()\n",
        "          timeToOpen = int((openingTime - currTime) / 60)\n",
        "          print(str(timeToOpen) + \" minutes til market open.\")\n",
        "          time.sleep(60)\n",
        "          isOpen = self.alpaca.get_clock().is_open\n",
        "\n",
        "    def trade(self):\n",
        "        state = self.get_state()\n",
        "\n",
        "        if self.drl_lib == 'elegantrl':\n",
        "            with torch.no_grad():\n",
        "                s_tensor = torch.as_tensor((state,), device=self.device)\n",
        "                a_tensor = self.act(s_tensor)\n",
        "                action = a_tensor.detach().cpu().numpy()[0]\n",
        "            action = (action * self.max_stock).astype(int)\n",
        "\n",
        "        elif self.drl_lib == 'rllib':\n",
        "            action = self.agent.compute_single_action(state)\n",
        "\n",
        "        elif self.drl_lib == 'stable_baselines3':\n",
        "            action = self.model.predict(state)[0]\n",
        "\n",
        "        else:\n",
        "            raise ValueError('The DRL library input is NOT supported yet. Please check your input.')\n",
        "\n",
        "        self.stocks_cd += 1\n",
        "        if self.turbulence_bool == 0:\n",
        "            min_action = 10  # stock_cd\n",
        "            threads = []\n",
        "            for index in np.where(action < -min_action)[0]:  # sell_index:\n",
        "                sell_num_shares = min(self.stocks[index], -action[index])\n",
        "                qty =  abs(int(sell_num_shares))\n",
        "                respSO = []\n",
        "                tSubmitOrder = threading.Thread(target=self.submitOrder(qty, self.stockUniverse[index], 'sell', respSO))\n",
        "                tSubmitOrder.start()\n",
        "                threads.append(tSubmitOrder)    # record thread for joining later\n",
        "                self.cash = float(self.alpaca.get_account().cash)\n",
        "                self.stocks_cd[index] = 0\n",
        "\n",
        "            for x in threads:   #  wait for all threads to complete\n",
        "                x.join()\n",
        "\n",
        "            threads = []\n",
        "            for index in np.where(action > min_action)[0]:  # buy_index:\n",
        "                if self.cash < 0:\n",
        "                    tmp_cash = 0\n",
        "                else:\n",
        "                    tmp_cash = self.cash\n",
        "                buy_num_shares = min(tmp_cash // self.price[index], abs(int(action[index])))\n",
        "                if (buy_num_shares != buy_num_shares): # if buy_num_change = nan\n",
        "                    qty = 0 # set to 0 quantity\n",
        "                else:\n",
        "                    qty = abs(int(buy_num_shares))\n",
        "                qty = abs(int(buy_num_shares))\n",
        "                respSO = []\n",
        "                tSubmitOrder = threading.Thread(target=self.submitOrder(qty, self.stockUniverse[index], 'buy', respSO))\n",
        "                tSubmitOrder.start()\n",
        "                threads.append(tSubmitOrder)    # record thread for joining later\n",
        "                self.cash = float(self.alpaca.get_account().cash)\n",
        "                self.stocks_cd[index] = 0\n",
        "\n",
        "            for x in threads:   #  wait for all threads to complete\n",
        "                x.join()\n",
        "\n",
        "        else:  # sell all when turbulence\n",
        "            threads = []\n",
        "            positions = self.alpaca.list_positions()\n",
        "            for position in positions:\n",
        "                if(position.side == 'long'):\n",
        "                    orderSide = 'sell'\n",
        "                else:\n",
        "                    orderSide = 'buy'\n",
        "                qty = abs(int(float(position.qty)))\n",
        "                respSO = []\n",
        "                tSubmitOrder = threading.Thread(target=self.submitOrder(qty, position.symbol, orderSide, respSO))\n",
        "                tSubmitOrder.start()\n",
        "                threads.append(tSubmitOrder)    # record thread for joining later\n",
        "\n",
        "            for x in threads:   #  wait for all threads to complete\n",
        "                x.join()\n",
        "\n",
        "            self.stocks_cd[:] = 0\n",
        "\n",
        "\n",
        "    def get_state(self):\n",
        "        alpaca = AlpacaProcessor(api=self.alpaca)\n",
        "        price, tech, turbulence = alpaca.fetch_latest_data(ticker_list = self.stockUniverse, time_interval='1Min',\n",
        "                                                     tech_indicator_list=self.tech_indicator_list)\n",
        "        turbulence_bool = 1 if turbulence >= self.turbulence_thresh else 0\n",
        "\n",
        "        turbulence = (self.sigmoid_sign(turbulence, self.turbulence_thresh) * 2 ** -5).astype(np.float32)\n",
        "\n",
        "        tech = tech * 2 ** -7\n",
        "        positions = self.alpaca.list_positions()\n",
        "        stocks = [0] * len(self.stockUniverse)\n",
        "        for position in positions:\n",
        "            ind = self.stockUniverse.index(position.symbol)\n",
        "            stocks[ind] = ( abs(int(float(position.qty))))\n",
        "\n",
        "        stocks = np.asarray(stocks, dtype = float)\n",
        "        cash = float(self.alpaca.get_account().cash)\n",
        "        self.cash = cash\n",
        "        self.stocks = stocks\n",
        "        self.turbulence_bool = turbulence_bool\n",
        "        self.price = price\n",
        "\n",
        "\n",
        "\n",
        "        amount = np.array(self.cash * (2 ** -12), dtype=np.float32)\n",
        "        scale = np.array(2 ** -6, dtype=np.float32)\n",
        "        state = np.hstack((amount,\n",
        "                    turbulence,\n",
        "                    self.turbulence_bool,\n",
        "                    price * scale,\n",
        "                    self.stocks * scale,\n",
        "                    self.stocks_cd,\n",
        "                    tech,\n",
        "                    )).astype(np.float32)\n",
        "        state[np.isnan(state)] = 0.0\n",
        "        state[np.isinf(state)] = 0.0\n",
        "        print(len(self.stockUniverse))\n",
        "        return state\n",
        "\n",
        "    def submitOrder(self, qty, stock, side, resp):\n",
        "        if(qty > 0):\n",
        "          try:\n",
        "            self.alpaca.submit_order(stock, qty, side, \"market\", \"day\")\n",
        "            print(\"Market order of | \" + str(qty) + \" \" + stock + \" \" + side + \" | completed.\")\n",
        "            resp.append(True)\n",
        "          except:\n",
        "            print(\"Order of | \" + str(qty) + \" \" + stock + \" \" + side + \" | did not go through.\")\n",
        "            resp.append(False)\n",
        "        else:\n",
        "          print(\"Quantity is 0, order of | \" + str(qty) + \" \" + stock + \" \" + side + \" | not completed.\")\n",
        "          resp.append(True)\n",
        "\n",
        "    @staticmethod\n",
        "    def sigmoid_sign(ary, thresh):\n",
        "        def sigmoid(x):\n",
        "            return 1 / (1 + np.exp(-x * np.e)) - 0.5\n",
        "\n",
        "        return sigmoid(ary / thresh) * thresh\n",
        "\n",
        "class StockEnvEmpty(gym.Env):\n",
        "    #Empty Env used for loading rllib agent\n",
        "    def __init__(self,config):\n",
        "      state_dim = config['state_dim']\n",
        "      action_dim = config['action_dim']\n",
        "      self.env_num = 1\n",
        "      self.max_step = 10000\n",
        "      self.env_name = 'StockEnvEmpty'\n",
        "      self.state_dim = state_dim\n",
        "      self.action_dim = action_dim\n",
        "      self.if_discrete = False\n",
        "      self.target_return = 9999\n",
        "      self.observation_space = gym.spaces.Box(low=-3000, high=3000, shape=(state_dim,), dtype=np.float32)\n",
        "      self.action_space = gym.spaces.Box(low=-1, high=1, shape=(action_dim,), dtype=np.float32)\n",
        "\n",
        "    def reset(self):\n",
        "        return\n",
        "\n",
        "    def step(self, actions):\n",
        "        return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "os4C4-4H7ns7"
      },
      "source": [
        "## Run Paper trading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7nw0i-0UN3-7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e22115c-deda-4a00-c93f-a1813560ae79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['AXP', 'AMGN', 'AAPL', 'BA', 'CAT', 'CSCO', 'CVX', 'GS', 'HD', 'HON', 'IBM', 'INTC', 'JNJ', 'KO', 'JPM', 'MCD', 'MMM', 'MRK', 'MSFT', 'NKE', 'PG', 'TRV', 'UNH', 'CRM', 'VZ', 'V', 'WBA', 'WMT', 'DIS', 'DOW']\n"
          ]
        }
      ],
      "source": [
        "print(DOW_30_TICKER)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YsSBK9ION1t6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f300ee2-348c-4fa3-875f-0a221f27d4ac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "333"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "state_dim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xYtSv6P1N247",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d29cded9-8782-444d-b020-6c33da355311"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "action_dim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kl9nulnAJtiI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "63d15341-d390-44af-9a29-fbedd7d61c0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| load actor from: ./papertrading_erl_retrain/actor.pth\n",
            "Waiting for market to open...\n",
            "123 minutes til market open.\n",
            "122 minutes til market open.\n",
            "121 minutes til market open.\n",
            "120 minutes til market open.\n",
            "119 minutes til market open.\n",
            "118 minutes til market open.\n",
            "117 minutes til market open.\n",
            "116 minutes til market open.\n",
            "115 minutes til market open.\n",
            "114 minutes til market open.\n",
            "113 minutes til market open.\n",
            "112 minutes til market open.\n",
            "111 minutes til market open.\n",
            "110 minutes til market open.\n",
            "109 minutes til market open.\n",
            "108 minutes til market open.\n",
            "107 minutes til market open.\n",
            "106 minutes til market open.\n",
            "105 minutes til market open.\n",
            "104 minutes til market open.\n",
            "103 minutes til market open.\n",
            "102 minutes til market open.\n",
            "101 minutes til market open.\n",
            "100 minutes til market open.\n",
            "99 minutes til market open.\n",
            "98 minutes til market open.\n",
            "97 minutes til market open.\n",
            "96 minutes til market open.\n",
            "95 minutes til market open.\n",
            "94 minutes til market open.\n",
            "93 minutes til market open.\n",
            "92 minutes til market open.\n",
            "91 minutes til market open.\n",
            "90 minutes til market open.\n",
            "89 minutes til market open.\n",
            "88 minutes til market open.\n",
            "87 minutes til market open.\n",
            "86 minutes til market open.\n",
            "85 minutes til market open.\n",
            "84 minutes til market open.\n",
            "83 minutes til market open.\n",
            "82 minutes til market open.\n",
            "81 minutes til market open.\n",
            "80 minutes til market open.\n",
            "79 minutes til market open.\n",
            "78 minutes til market open.\n",
            "77 minutes til market open.\n",
            "76 minutes til market open.\n",
            "75 minutes til market open.\n",
            "74 minutes til market open.\n",
            "73 minutes til market open.\n",
            "72 minutes til market open.\n",
            "71 minutes til market open.\n",
            "70 minutes til market open.\n",
            "69 minutes til market open.\n",
            "68 minutes til market open.\n",
            "67 minutes til market open.\n",
            "66 minutes til market open.\n",
            "65 minutes til market open.\n",
            "64 minutes til market open.\n",
            "63 minutes til market open.\n",
            "62 minutes til market open.\n",
            "61 minutes til market open.\n",
            "59 minutes til market open.\n",
            "58 minutes til market open.\n",
            "57 minutes til market open.\n",
            "56 minutes til market open.\n",
            "55 minutes til market open.\n",
            "54 minutes til market open.\n",
            "53 minutes til market open.\n",
            "52 minutes til market open.\n",
            "51 minutes til market open.\n",
            "50 minutes til market open.\n",
            "49 minutes til market open.\n",
            "48 minutes til market open.\n",
            "47 minutes til market open.\n",
            "46 minutes til market open.\n",
            "45 minutes til market open.\n",
            "44 minutes til market open.\n",
            "43 minutes til market open.\n",
            "42 minutes til market open.\n",
            "41 minutes til market open.\n",
            "40 minutes til market open.\n",
            "39 minutes til market open.\n",
            "38 minutes til market open.\n",
            "37 minutes til market open.\n",
            "36 minutes til market open.\n",
            "35 minutes til market open.\n",
            "34 minutes til market open.\n",
            "33 minutes til market open.\n",
            "32 minutes til market open.\n",
            "31 minutes til market open.\n",
            "30 minutes til market open.\n",
            "29 minutes til market open.\n",
            "28 minutes til market open.\n",
            "27 minutes til market open.\n",
            "26 minutes til market open.\n",
            "25 minutes til market open.\n",
            "24 minutes til market open.\n",
            "23 minutes til market open.\n",
            "22 minutes til market open.\n",
            "21 minutes til market open.\n",
            "20 minutes til market open.\n",
            "19 minutes til market open.\n",
            "18 minutes til market open.\n",
            "17 minutes til market open.\n",
            "16 minutes til market open.\n",
            "15 minutes til market open.\n",
            "14 minutes til market open.\n",
            "13 minutes til market open.\n",
            "12 minutes til market open.\n",
            "11 minutes til market open.\n",
            "10 minutes til market open.\n",
            "9 minutes til market open.\n",
            "8 minutes til market open.\n",
            "7 minutes til market open.\n",
            "6 minutes til market open.\n",
            "5 minutes til market open.\n",
            "4 minutes til market open.\n",
            "3 minutes til market open.\n",
            "2 minutes til market open.\n",
            "1 minutes til market open.\n",
            "0 minutes til market open.\n",
            "Market opened.\n",
            "Started adding Indicators\n",
            "Running Loop\n",
            "Restore Timestamps\n",
            "Finished adding Indicators\n",
            "30\n",
            "Quantity is 0, order of | 0 CAT sell | not completed.\n",
            "Quantity is 0, order of | 0 CVX sell | not completed.\n",
            "Quantity is 0, order of | 0 HON sell | not completed.\n",
            "Quantity is 0, order of | 0 MRK sell | not completed.\n",
            "Market order of | 24 AAPL buy | completed.\n",
            "Market order of | 16 CSCO buy | completed.\n",
            "Market order of | 47 IBM buy | completed.\n",
            "Market order of | 21 MMM buy | completed.\n",
            "Market order of | 20 MSFT buy | completed.\n",
            "Market order of | 15 NKE buy | completed.\n",
            "Market order of | 12 CRM buy | completed.\n",
            "Market order of | 14 VZ buy | completed.\n",
            "Market order of | 21 WBA buy | completed.\n",
            "Market order of | 22 WMT buy | completed.\n",
            "Market order of | 38 DOW buy | completed.\n",
            "Started adding Indicators\n",
            "Running Loop\n",
            "Restore Timestamps\n",
            "Finished adding Indicators\n",
            "30\n",
            "Quantity is 0, order of | 0 AXP sell | not completed.\n",
            "Quantity is 0, order of | 0 AMGN sell | not completed.\n",
            "Quantity is 0, order of | 0 CVX sell | not completed.\n",
            "Quantity is 0, order of | 0 HD sell | not completed.\n",
            "Quantity is 0, order of | 0 HON sell | not completed.\n",
            "Quantity is 0, order of | 0 MRK sell | not completed.\n",
            "Quantity is 0, order of | 0 UNH sell | not completed.\n",
            "Market order of | 27 AAPL buy | completed.\n",
            "Market order of | 17 CSCO buy | completed.\n",
            "Market order of | 52 IBM buy | completed.\n",
            "Market order of | 13 KO buy | completed.\n",
            "Market order of | 11 MMM buy | completed.\n",
            "Market order of | 15 MSFT buy | completed.\n",
            "Market order of | 15 NKE buy | completed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-7ecc7f73005e>:223: RuntimeWarning: divide by zero encountered in scalar floor_divide\n",
            "  buy_num_shares = min(tmp_cash // self.price[index], abs(int(action[index])))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Market order of | 11 TRV buy | completed.\n",
            "Market order of | 15 CRM buy | completed.\n",
            "Market order of | 18 VZ buy | completed.\n",
            "Market order of | 17 WBA buy | completed.\n",
            "Market order of | 22 WMT buy | completed.\n",
            "Market order of | 30 DOW buy | completed.\n",
            "Started adding Indicators\n",
            "Running Loop\n",
            "Restore Timestamps\n",
            "Finished adding Indicators\n",
            "30\n",
            "Quantity is 0, order of | 0 AMGN sell | not completed.\n",
            "Quantity is 0, order of | 0 CVX sell | not completed.\n",
            "Quantity is 0, order of | 0 HD sell | not completed.\n",
            "Quantity is 0, order of | 0 MCD sell | not completed.\n",
            "Quantity is 0, order of | 0 MRK sell | not completed.\n",
            "Quantity is 0, order of | 0 UNH sell | not completed.\n",
            "Market order of | 18 AAPL buy | completed.\n",
            "Market order of | 58 IBM buy | completed.\n",
            "Market order of | 13 KO buy | completed.\n",
            "Market order of | 20 MMM buy | completed.\n",
            "Market order of | 18 MSFT buy | completed.\n",
            "Market order of | 12 NKE buy | completed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-7ecc7f73005e>:223: RuntimeWarning: divide by zero encountered in scalar floor_divide\n",
            "  buy_num_shares = min(tmp_cash // self.price[index], abs(int(action[index])))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Market order of | 15 TRV buy | completed.\n",
            "Market order of | 12 CRM buy | completed.\n",
            "Market order of | 17 VZ buy | completed.\n",
            "Market order of | 14 WBA buy | completed.\n",
            "Market order of | 28 WMT buy | completed.\n",
            "Market order of | 18 DOW buy | completed.\n",
            "Started adding Indicators\n",
            "Running Loop\n",
            "Restore Timestamps\n",
            "Finished adding Indicators\n",
            "30\n",
            "Quantity is 0, order of | 0 AMGN sell | not completed.\n",
            "Quantity is 0, order of | 0 CVX sell | not completed.\n",
            "Quantity is 0, order of | 0 HD sell | not completed.\n",
            "Quantity is 0, order of | 0 MCD sell | not completed.\n",
            "Quantity is 0, order of | 0 MRK sell | not completed.\n",
            "Quantity is 0, order of | 0 PG sell | not completed.\n",
            "Quantity is 0, order of | 0 UNH sell | not completed.\n",
            "Quantity is 0, order of | 0 AXP buy | not completed.\n",
            "Quantity is 0, order of | 0 AAPL buy | not completed.\n",
            "Quantity is 0, order of | 0 IBM buy | not completed.\n",
            "Quantity is 0, order of | 0 KO buy | not completed.\n",
            "Quantity is 0, order of | 0 MMM buy | not completed.\n",
            "Quantity is 0, order of | 0 MSFT buy | not completed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-7ecc7f73005e>:223: RuntimeWarning: invalid value encountered in scalar floor_divide\n",
            "  buy_num_shares = min(tmp_cash // self.price[index], abs(int(action[index])))\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "cannot convert float NaN to integer",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-ecdbcd758cb2>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m                                        \u001b[0mturbulence_thresh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                                        max_stock=1e2)\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mpaper_trading_erl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-24-7ecc7f73005e>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrade\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m             \u001b[0mlast_equity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpaca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_account\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_equity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0mcur_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-7ecc7f73005e>\u001b[0m in \u001b[0;36mtrade\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    226\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m                     \u001b[0mqty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuy_num_shares\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m                 \u001b[0mqty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuy_num_shares\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m                 \u001b[0mrespSO\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m                 \u001b[0mtSubmitOrder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthreading\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mThread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmitOrder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstockUniverse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'buy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrespSO\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot convert float NaN to integer"
          ]
        }
      ],
      "source": [
        "paper_trading_erl = AlpacaPaperTrading(ticker_list = DOW_30_TICKER,\n",
        "                                       time_interval = '1Min',\n",
        "                                       drl_lib = 'elegantrl',\n",
        "                                       agent = 'ppo',\n",
        "                                       cwd = './papertrading_erl_retrain',\n",
        "                                       net_dim = ERL_PARAMS['net_dimension'],\n",
        "                                       state_dim = state_dim,\n",
        "                                       action_dim= action_dim,\n",
        "                                       API_KEY = API_KEY,\n",
        "                                       API_SECRET = API_SECRET,\n",
        "                                       API_BASE_URL = API_BASE_URL,\n",
        "                                       tech_indicator_list = INDICATORS,\n",
        "                                       turbulence_thresh=30,\n",
        "                                       max_stock=1e2)\n",
        "paper_trading_erl.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srzBZfYEUI1O"
      },
      "source": [
        "# Part 4: Check Portfolio Performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "chovN1UhTAht"
      },
      "outputs": [],
      "source": [
        "import alpaca_trade_api as tradeapi\n",
        "import exchange_calendars as tc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pytz\n",
        "import yfinance as yf\n",
        "import matplotlib.ticker as ticker\n",
        "import matplotlib.dates as mdates\n",
        "from datetime import datetime as dt\n",
        "from finrl.plot import backtest_stats\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CaofxMNCfAR1"
      },
      "outputs": [],
      "source": [
        "def get_trading_days(start, end):\n",
        "    nyse = tc.get_calendar('NYSE')\n",
        "    df = nyse.sessions_in_range(pd.Timestamp(start),\n",
        "                                pd.Timestamp(end))\n",
        "    trading_days = []\n",
        "    for day in df:\n",
        "        trading_days.append(str(day)[:10])\n",
        "\n",
        "    return trading_days\n",
        "\n",
        "def alpaca_history(key, secret, url, start, end):\n",
        "    api = tradeapi.REST(key, secret, url, 'v2')\n",
        "    trading_days = get_trading_days(start, end)\n",
        "    df = pd.DataFrame()\n",
        "\n",
        "    for day in trading_days:\n",
        "        #df = df.append(api.get_portfolio_history(date_start = day,timeframe='5Min').df.iloc[:78])\n",
        "        df= pd.concat([df,api.get_portfolio_history(date_start = day,timeframe='1D').df.iloc[:78]],ignore_index=True)\n",
        "\n",
        "    # equities = df.equity.values\n",
        "    # if equities[0] != 0:\n",
        "    #   cumu_returns = equities/equities[0]\n",
        "    #cumu_returns = cumu_returns[~np.isnan(cumu_returns)]\n",
        "    equities = df.equity.values\n",
        "    equities = equities[~np.isnan(equities)]  # Filter out NaN values\n",
        "    if equities[0] != 0:\n",
        "        cumu_returns = equities / equities[0]\n",
        "    else:\n",
        "        cumu_returns = equities\n",
        "\n",
        "    return df, cumu_returns\n",
        "\n",
        "def DIA_history(start):\n",
        "    data_df = yf.download(['^DJI'],start=start, interval=\"1D\")\n",
        "    data_df = data_df.iloc[:]\n",
        "    baseline_returns = data_df['Adj Close'].values/data_df['Adj Close'].values[0]\n",
        "    return data_df, baseline_returns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CHiZRVpURpx"
      },
      "source": [
        "## Get cumulative return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_YT7v-LSdfV"
      },
      "outputs": [],
      "source": [
        "df_erl, cumu_erl = alpaca_history(key=API_KEY,\n",
        "                                  secret=API_SECRET,\n",
        "                                  url=API_BASE_URL,\n",
        "                                  start='2022-09-01', #must be within 1 month\n",
        "                                  end='2022-09-12') #change the date if error occurs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IMcQjwHOS6Zb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0e46e44-7782-4760-b914-791623bb2543"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%%**********************]  1 of 1 completed\n"
          ]
        }
      ],
      "source": [
        "df_djia, cumu_djia = DIA_history(start='2022-09-01')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJXPwmx9Ts5o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "279200c2-013e-4f5a-e7ee-93f622181846"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     profit_loss profit_loss_pct  equity\n",
              "148          0.0            None     0.0\n",
              "149          0.0            None     0.0\n",
              "150          0.0            None     0.0\n",
              "151          0.0            None     0.0\n",
              "152          0.0            None     0.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-deeb17ca-d066-4563-90cf-39b92065bb06\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>profit_loss</th>\n",
              "      <th>profit_loss_pct</th>\n",
              "      <th>equity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>0.0</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>0.0</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>0.0</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151</th>\n",
              "      <td>0.0</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>152</th>\n",
              "      <td>0.0</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-deeb17ca-d066-4563-90cf-39b92065bb06')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-deeb17ca-d066-4563-90cf-39b92065bb06 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-deeb17ca-d066-4563-90cf-39b92065bb06');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3f448972-0f2e-4af7-9904-c280b465d1db\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3f448972-0f2e-4af7-9904-c280b465d1db')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3f448972-0f2e-4af7-9904-c280b465d1db button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "repr_error": "0"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "df_erl.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o1Iaw90FTNfU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87ec0b63-98bd-40eb-8a2f-24e552979686"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len of erl return:  153\n",
            "len of dia return:  153\n"
          ]
        }
      ],
      "source": [
        "returns_erl = cumu_erl -1\n",
        "returns_dia = cumu_djia - 1\n",
        "returns_dia = returns_dia[:returns_erl.shape[0]]\n",
        "print('len of erl return: ', returns_erl.shape[0])\n",
        "print('len of dia return: ', returns_dia.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2IawaMsDwZni",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "627b6eee-8e95-4292-af60-29428a9fa4aa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
              "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
              "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
              "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
              "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
              "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
              "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
              "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
              "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
              "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
              "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
              "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "returns_erl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Z0LEm7KUZ5W"
      },
      "source": [
        "## plot and save"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Foqk1wIQTQJ3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f8393b5-df83-4f58-a432-ce5d9da3998e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-36-e8901d8304ea>:19: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  ax.xaxis.set_major_formatter(ticker.FixedFormatter(['','10-19','','10-20',\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(dpi=1000)\n",
        "plt.grid()\n",
        "plt.grid(which='minor', axis='y')\n",
        "plt.title('Stock Trading (Paper trading)', fontsize=20)\n",
        "plt.plot(returns_erl, label = 'ElegantRL Agent', color = 'red')\n",
        "#plt.plot(returns_sb3, label = 'Stable-Baselines3 Agent', color = 'blue' )\n",
        "#plt.plot(returns_rllib, label = 'RLlib Agent', color = 'green')\n",
        "plt.plot(returns_dia, label = 'DJIA', color = 'grey')\n",
        "plt.ylabel('Return', fontsize=16)\n",
        "plt.xlabel('Year 2021', fontsize=16)\n",
        "plt.xticks(size = 14)\n",
        "plt.yticks(size = 14)\n",
        "ax = plt.gca()\n",
        "ax.xaxis.set_major_locator(ticker.MultipleLocator(78))\n",
        "ax.xaxis.set_minor_locator(ticker.MultipleLocator(6))\n",
        "ax.yaxis.set_minor_locator(ticker.MultipleLocator(0.005))\n",
        "ax.yaxis.set_major_formatter(ticker.PercentFormatter(xmax=1, decimals=2))\n",
        "ax.xaxis.set_major_formatter(ticker.FixedFormatter(['','10-19','','10-20',\n",
        "                                                    '','10-21','','10-22']))\n",
        "plt.legend(fontsize=10.5)\n",
        "plt.savefig('papertrading_stock.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_LsHVj_TZGL"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "0EVJIQUR6_fu",
        "9tzAw9k26nAC",
        "zjLda8No6pvI"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "005d14239094016f48a03a57365c4ccb734e3f38c20ed0ca595d84f773bc39cd"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}